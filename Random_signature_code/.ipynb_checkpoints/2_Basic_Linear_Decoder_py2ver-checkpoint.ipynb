{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import data_tool as dt\n",
    "import time\n",
    "\n",
    "epoch_count = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor([4 6], shape=(2,), dtype=int32)\n",
      "tf.Tensor(25, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(13, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.add(1, 2))\n",
    "print(tf.add([1, 2], [3, 4]))\n",
    "print(tf.square(5))\n",
    "print(tf.reduce_sum([1, 2, 3]))\n",
    "\n",
    "# Operator overloading is also supported\n",
    "print(tf.square(2) + tf.square(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[2 3]], shape=(1, 2), dtype=int32)\n",
      "(1, 2)\n",
      "<dtype: 'int32'>\n"
     ]
    }
   ],
   "source": [
    "x = tf.matmul([[1]], [[2, 3]])\n",
    "print(x)\n",
    "print(x.shape)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow operations convert numpy arrays to Tensors automatically\n",
      "tf.Tensor(\n",
      "[[42. 42. 42.]\n",
      " [42. 42. 42.]\n",
      " [42. 42. 42.]], shape=(3, 3), dtype=float64)\n",
      "And NumPy operations convert Tensors to numpy arrays automatically\n",
      "[[43. 43. 43.]\n",
      " [43. 43. 43.]\n",
      " [43. 43. 43.]]\n",
      "The .numpy() method explicitly converts a Tensor to a numpy array\n",
      "[[42. 42. 42.]\n",
      " [42. 42. 42.]\n",
      " [42. 42. 42.]]\n"
     ]
    }
   ],
   "source": [
    "ndarray = np.ones([3, 3])\n",
    "\n",
    "print(\"TensorFlow operations convert numpy arrays to Tensors automatically\")\n",
    "tensor = tf.multiply(ndarray, 42)\n",
    "print(tensor)\n",
    "\n",
    "\n",
    "print(\"And NumPy operations convert Tensors to numpy arrays automatically\")\n",
    "print(np.add(tensor, 1))\n",
    "\n",
    "print(\"The .numpy() method explicitly converts a Tensor to a numpy array\")\n",
    "print(tensor.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there a GPU available:  []\n",
      "Is the Tensor on GPU #0:   False\n"
     ]
    }
   ],
   "source": [
    "x = tf.random.uniform([3, 3])\n",
    "\n",
    "print(\"Is there a GPU available: \"),\n",
    "print(tf.config.experimental.list_physical_devices(\"GPU\"))\n",
    "\n",
    "print(\"Is the Tensor on GPU #0:  \"),\n",
    "print(x.device.endswith('GPU:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On CPU:\n",
      "10 loops: 243.91ms\n"
     ]
    }
   ],
   "source": [
    "def time_matmul(x):\n",
    "  start = time.time()\n",
    "  for loop in range(10):\n",
    "    tf.matmul(x, x)\n",
    "\n",
    "  result = time.time()-start\n",
    "\n",
    "  print(\"10 loops: {:0.2f}ms\".format(1000*result))\n",
    "\n",
    "# Force execution on CPU\n",
    "print(\"On CPU:\")\n",
    "with tf.device(\"CPU:0\"):\n",
    "  x = tf.random.uniform([1000, 1000])\n",
    "  assert x.device.endswith(\"CPU:0\")\n",
    "  time_matmul(x)\n",
    "\n",
    "# Force execution on GPU #0 if available\n",
    "if tf.config.experimental.list_physical_devices(\"GPU\"):\n",
    "  print(\"On GPU:\")\n",
    "  with tf.device(\"GPU:0\"): # Or GPU:1 for the 2nd GPU, GPU:2 for the 3rd etc.\n",
    "    x = tf.random.uniform([1000, 1000])\n",
    "    assert x.device.endswith(\"GPU:0\")\n",
    "    time_matmul(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tensors = tf.data.Dataset.from_tensor_slices([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "# Create a CSV file\n",
    "import tempfile\n",
    "_, filename = tempfile.mkstemp()\n",
    "\n",
    "with open(filename, 'w') as f:\n",
    "  f.write(\"\"\"Line 1\n",
    "Line 2\n",
    "Line 3\n",
    "  \"\"\")\n",
    "\n",
    "ds_file = tf.data.TextLineDataset(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 50\n",
    "T = 100\n",
    "phi = dt.get_random_binary_signature_matrix(T, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y, _, _ = dt.get_dataset(1000, phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 50\n",
    "total = 100\n",
    "batch_size = 1000\n",
    "p = 0.1\n",
    "phi = np.array(get_matrix(total, l), 'float32')\n",
    "ave_power = get_avege_power(p,phi,total,100000)\n",
    "# Training Parameters\n",
    "learning_rate = 0.001\n",
    "display_step = 1000\n",
    "train_sigma = get_sigma_by_snr(10, ave_power, l)\n",
    "print(ave_power)\n",
    "# Network Parameters\n",
    "num_input = l # input of decoder\n",
    "num_hidden_decoder = (l + total)# decoder layer num features\n",
    "num_output = total # output of decoder or this NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "def get_sigma_by_snr(snr, ave_power, signal_l):\n",
    "    sigma2 = ave_power / (signal_l * np.power(10.0, snr/10.0))\n",
    "    sigma = np.sqrt(sigma2)\n",
    "    return sigma\n",
    "\n",
    "def get_final_result_for_detector(output):\n",
    "    r = np.ones_like(output[0])\n",
    "    for i in range(output[0].size):\n",
    "        if output[0][i] <= 0.5:\n",
    "            r[i] = 0\n",
    "    return r\n",
    "\n",
    "def get_final_result_for_decoder(output):\n",
    "    r = np.ones_like(output[0])\n",
    "    for i in range(output[0].size):\n",
    "        if output[0][i] <= 0.05:\n",
    "            r[i] = 0\n",
    "    return r\n",
    "\n",
    "def get_matrix(size, length):\n",
    "    ma = 1-2*np.random.binomial(1,0.5, (size,length))\n",
    "    mb = np.random.binomial(1,0.5, (size,length))\n",
    "    return ma*mb\n",
    "\n",
    "def get_batch(data_size, p, phi, total):\n",
    "    phi = np.transpose(phi)\n",
    "    x = np.random.binomial(n=1, p=p, size=(total,data_size))\n",
    "    h_x = np.random.rayleigh(1, size=(total,data_size)) * x\n",
    "    phi_h_x = np.dot(phi, h_x)\n",
    "    phi_x = np.dot(phi, x)\n",
    "    return np.transpose(phi_x), np.transpose(x), np.transpose(phi_h_x), np.transpose(h_x)\n",
    "\n",
    "def get_avege_power(p, phi, total, test_time):\n",
    "    phi = np.transpose(phi)\n",
    "    sum=0\n",
    "    for i in range(test_time):\n",
    "        x = np.random.binomial(n=1, p=p, size=(total,1))\n",
    "        phi_x = np.dot(phi, x)\n",
    "        sum += np.power(np.linalg.norm(phi_x, ord=2), 2)\n",
    "    return sum/test_time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
