{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import data_tool as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_number = 100\n",
    "code_length = 50\n",
    "epoch_number = 30\n",
    "batch_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMSE_Accuracy(keras.metrics.Metric):\n",
    "    def __init__(self, name=\"nmse_accuracy\", **kwargs):\n",
    "        super(NMSE_Accuracy, self).__init__(name=name, **kwargs)\n",
    "        self.sum_nmse = self.add_weight(name=\"sum_nmse\", initializer=\"zeros\")\n",
    "        self.sample_number = self.add_weight(name=\"sample_number\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        diff = y_pred - y_true\n",
    "        fenmu = tf.reduce_sum(tf.pow(y_true, 2), 1)\n",
    "        current_nmse = tf.reduce_sum(tf.reduce_sum(tf.pow(diff, 2), 1) / fenmu)\n",
    "        current_nmse = tf.where(tf.math.is_nan(current_nmse)|tf.math.is_inf(current_nmse), tf.zeros_like(current_nmse), current_nmse)\n",
    "        current_nmse = tf.cast(current_nmse, \"float32\")\n",
    "        self.sum_nmse.assign_add(current_nmse)\n",
    "#         current_sample_number = y_true.shape[0]\n",
    "        current_sample_number = tf.math.count_nonzero(fenmu)\n",
    "        current_sample_number = tf.cast(current_sample_number, \"float32\")\n",
    "        self.sample_number.assign_add(current_sample_number)\n",
    "\n",
    "    def result(self):\n",
    "        return 10 * (tf.math.log(self.sum_nmse / self.sample_number) / tf.math.log(10.))\n",
    "\n",
    "    def reset_states(self):\n",
    "        # The state of the metric will be reset at the start of each epoch.\n",
    "        self.sum_nmse.assign(0.0)\n",
    "        self.sample_number.assign(0.0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bp1 (BatchNormalization)     (3, 50)                   200       \n",
      "_________________________________________________________________\n",
      "layer1 (Dense)               (3, 150)                  7650      \n",
      "_________________________________________________________________\n",
      "bp2 (BatchNormalization)     (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "bp3 (BatchNormalization)     (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer3 (Dense)               (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "pb4 (BatchNormalization)     (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer4 (Dense)               (3, 100)                  15100     \n",
      "_________________________________________________________________\n",
      "bp1_2 (BatchNormalization)   (3, 100)                  400       \n",
      "_________________________________________________________________\n",
      "layer1_2 (Dense)             (3, 150)                  15150     \n",
      "_________________________________________________________________\n",
      "bp2_2 (BatchNormalization)   (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer2_2 (Dense)             (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "bp3_2 (BatchNormalization)   (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer3_2 (Dense)             (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "pb4_2 (BatchNormalization)   (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer4_2 (Dense)             (3, 100)                  15100     \n",
      "_________________________________________________________________\n",
      "bp1_3 (BatchNormalization)   (3, 100)                  400       \n",
      "_________________________________________________________________\n",
      "layer1_3 (Dense)             (3, 150)                  15150     \n",
      "_________________________________________________________________\n",
      "bp2_3 (BatchNormalization)   (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer2_3 (Dense)             (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "bp3_3 (BatchNormalization)   (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer3_3 (Dense)             (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "pb4_3 (BatchNormalization)   (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer4_3 (Dense)             (3, 100)                  15100     \n",
      "_________________________________________________________________\n",
      "bp1_4 (BatchNormalization)   (3, 100)                  400       \n",
      "_________________________________________________________________\n",
      "layer1_4 (Dense)             (3, 150)                  15150     \n",
      "_________________________________________________________________\n",
      "bp2_4 (BatchNormalization)   (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer2_4 (Dense)             (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "bp3_4 (BatchNormalization)   (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer3_4 (Dense)             (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "pb4_4 (BatchNormalization)   (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer4_4 (Dense)             (3, 100)                  15100     \n",
      "_________________________________________________________________\n",
      "bp1_5 (BatchNormalization)   (3, 100)                  400       \n",
      "_________________________________________________________________\n",
      "layer1_5 (Dense)             (3, 150)                  15150     \n",
      "_________________________________________________________________\n",
      "bp2_5 (BatchNormalization)   (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer2_5 (Dense)             (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "bp3_5 (BatchNormalization)   (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer3_5 (Dense)             (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "pb4_5 (BatchNormalization)   (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer4_5 (Dense)             (3, 100)                  15100     \n",
      "=================================================================\n",
      "Total params: 381,050\n",
      "Trainable params: 375,650\n",
      "Non-trainable params: 5,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder = keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp1\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer1\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp2\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer2\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp3\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer3\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"pb4\"),\n",
    "        layers.Dense(user_number, activation=\"relu\", name=\"layer4\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp1_2\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer1_2\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp2_2\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer2_2\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp3_2\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer3_2\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"pb4_2\"),\n",
    "        layers.Dense(user_number, activation=\"relu\", name=\"layer4_2\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp1_3\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer1_3\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp2_3\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer2_3\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp3_3\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer3_3\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"pb4_3\"),\n",
    "        layers.Dense(user_number, activation=\"relu\", name=\"layer4_3\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp1_4\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer1_4\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp2_4\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer2_4\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp3_4\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer3_4\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"pb4_4\"),\n",
    "        layers.Dense(user_number, activation=\"relu\", name=\"layer4_4\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp1_5\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer1_5\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp2_5\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer2_5\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp3_5\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer3_5\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"pb4_5\"),\n",
    "        layers.Dense(user_number, activation=\"relu\", name=\"layer4_5\"),\n",
    "    ],name = 'decoder'\n",
    ")\n",
    "# Call model on a test input\n",
    "y = tf.ones((3, code_length))\n",
    "x_hat = decoder(y)\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "signature_matrix = dt.get_random_binary_signature_matrix(user_number, code_length)\n",
    "y_set, x_set, h_set = dt.get_dataset(2500000, signature_matrix, is_fading=1)\n",
    "y_set = y_set.astype(\"float32\")\n",
    "x_set = x_set.astype(\"float32\")\n",
    "h_set = h_set.astype(\"float32\")\n",
    "y_test, x_test, h_test = dt.get_dataset(10000, signature_matrix, is_fading=1)\n",
    "y_test = y_test.astype(\"float32\")\n",
    "x_test = x_test.astype(\"float32\")\n",
    "h_test = h_test.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2000/2000 [==============================] - 142s 68ms/step - loss: 0.1707 - nmse_accuracy: -0.8079 - val_loss: 0.1331 - val_nmse_accuracy: -1.9074\n",
      "Epoch 2/30\n",
      "2000/2000 [==============================] - 128s 64ms/step - loss: 0.1197 - nmse_accuracy: -2.3785 - val_loss: 0.1146 - val_nmse_accuracy: -2.6049\n",
      "Epoch 3/30\n",
      "2000/2000 [==============================] - 122s 61ms/step - loss: 0.1082 - nmse_accuracy: -2.8546 - val_loss: 0.1039 - val_nmse_accuracy: -3.0783\n",
      "Epoch 4/30\n",
      "2000/2000 [==============================] - 116s 58ms/step - loss: 0.0989 - nmse_accuracy: -3.2789 - val_loss: 0.0971 - val_nmse_accuracy: -3.3998\n",
      "Epoch 5/30\n",
      "2000/2000 [==============================] - 126s 63ms/step - loss: 0.0931 - nmse_accuracy: -3.5799 - val_loss: 0.0925 - val_nmse_accuracy: -3.5826\n",
      "Epoch 6/30\n",
      "2000/2000 [==============================] - 131s 65ms/step - loss: 0.0862 - nmse_accuracy: -3.9070 - val_loss: 0.0865 - val_nmse_accuracy: -3.9312\n",
      "Epoch 7/30\n",
      "2000/2000 [==============================] - 183s 92ms/step - loss: 0.0796 - nmse_accuracy: -4.3126 - val_loss: 0.0782 - val_nmse_accuracy: -4.4189\n",
      "Epoch 8/30\n",
      "2000/2000 [==============================] - 203s 101ms/step - loss: 0.0724 - nmse_accuracy: -4.7653 - val_loss: 0.0724 - val_nmse_accuracy: -4.7674\n",
      "Epoch 9/30\n",
      "2000/2000 [==============================] - 155s 78ms/step - loss: 0.0663 - nmse_accuracy: -5.1780 - val_loss: 0.0717 - val_nmse_accuracy: -4.7487\n",
      "Epoch 10/30\n",
      "2000/2000 [==============================] - 246s 123ms/step - loss: 0.0621 - nmse_accuracy: -5.4714 - val_loss: 0.0674 - val_nmse_accuracy: -5.0802\n",
      "Epoch 11/30\n",
      "2000/2000 [==============================] - 201s 101ms/step - loss: 0.0589 - nmse_accuracy: -5.7361 - val_loss: 0.0639 - val_nmse_accuracy: -5.3262\n",
      "Epoch 12/30\n",
      "2000/2000 [==============================] - 180s 90ms/step - loss: 0.0567 - nmse_accuracy: -5.8970 - val_loss: 0.0622 - val_nmse_accuracy: -5.4275\n",
      "Epoch 13/30\n",
      "2000/2000 [==============================] - 197s 99ms/step - loss: 0.0548 - nmse_accuracy: -6.0626 - val_loss: 0.0627 - val_nmse_accuracy: -5.3775\n",
      "Epoch 14/30\n",
      "2000/2000 [==============================] - 220s 110ms/step - loss: 0.0526 - nmse_accuracy: -6.2250 - val_loss: 53148.3203 - val_nmse_accuracy: 52.3530\n",
      "Epoch 15/30\n",
      "2000/2000 [==============================] - 205s 103ms/step - loss: 0.0506 - nmse_accuracy: -6.4437 - val_loss: 4.0978 - val_nmse_accuracy: 11.6577\n",
      "Epoch 16/30\n",
      "2000/2000 [==============================] - 191s 95ms/step - loss: 0.0500 - nmse_accuracy: -6.4741 - val_loss: 0.0589 - val_nmse_accuracy: -5.6478\n",
      "Epoch 17/30\n",
      "2000/2000 [==============================] - 183s 92ms/step - loss: 0.0496 - nmse_accuracy: -6.4790 - val_loss: 0.0536 - val_nmse_accuracy: -6.1404\n",
      "Epoch 18/30\n",
      "2000/2000 [==============================] - 176s 88ms/step - loss: 0.0485 - nmse_accuracy: -6.6520 - val_loss: 0.5076 - val_nmse_accuracy: 2.5445\n",
      "Epoch 19/30\n",
      "2000/2000 [==============================] - 173s 86ms/step - loss: 0.0465 - nmse_accuracy: -6.8255 - val_loss: 736861837890420736.0000 - val_nmse_accuracy: 182.2990\n",
      "Epoch 20/30\n",
      "2000/2000 [==============================] - 200s 100ms/step - loss: 0.0460 - nmse_accuracy: -6.8446 - val_loss: 54.6098 - val_nmse_accuracy: 21.5962\n",
      "Epoch 21/30\n",
      "2000/2000 [==============================] - 183s 92ms/step - loss: 0.0457 - nmse_accuracy: -6.8625 - val_loss: 0.0892 - val_nmse_accuracy: -5.0013\n",
      "Epoch 22/30\n",
      "2000/2000 [==============================] - 180s 90ms/step - loss: 0.0453 - nmse_accuracy: -6.9109 - val_loss: 0.0513 - val_nmse_accuracy: -6.3945\n",
      "Epoch 23/30\n",
      "2000/2000 [==============================] - 177s 89ms/step - loss: 0.0451 - nmse_accuracy: -6.9516 - val_loss: 0.0534 - val_nmse_accuracy: -6.0687\n",
      "Epoch 24/30\n",
      "2000/2000 [==============================] - 188s 94ms/step - loss: 0.0449 - nmse_accuracy: -6.9686 - val_loss: 0.0512 - val_nmse_accuracy: -6.3267\n",
      "Epoch 25/30\n",
      "2000/2000 [==============================] - 192s 96ms/step - loss: 0.0444 - nmse_accuracy: -7.0093 - val_loss: 0.0502 - val_nmse_accuracy: -6.4690\n",
      "Epoch 26/30\n",
      "2000/2000 [==============================] - 178s 89ms/step - loss: 0.0444 - nmse_accuracy: -7.0454 - val_loss: 0.0499 - val_nmse_accuracy: -6.4753\n",
      "Epoch 27/30\n",
      "2000/2000 [==============================] - 150s 75ms/step - loss: 0.0442 - nmse_accuracy: -7.0369 - val_loss: 0.0506 - val_nmse_accuracy: -6.3555\n",
      "Epoch 28/30\n",
      "2000/2000 [==============================] - 118s 59ms/step - loss: 0.0435 - nmse_accuracy: -7.1259 - val_loss: 0.0500 - val_nmse_accuracy: -6.4027\n",
      "Epoch 29/30\n",
      "2000/2000 [==============================] - 118s 59ms/step - loss: 0.0437 - nmse_accuracy: -7.1044 - val_loss: 0.0480 - val_nmse_accuracy: -6.6217\n",
      "Epoch 30/30\n",
      "2000/2000 [==============================] - 115s 57ms/step - loss: 0.0435 - nmse_accuracy: -7.0977 - val_loss: 1457.5690 - val_nmse_accuracy: 36.6253\n",
      "313/313 - 1s - loss: 0.0523 - nmse_accuracy: -6.0237e+00\n",
      "Test loss: 0.052348677068948746\n",
      "Test accuracy: -6.023699760437012\n"
     ]
    }
   ],
   "source": [
    "decoder.compile(\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    metrics=NMSE_Accuracy(),\n",
    ")\n",
    "\n",
    "history = decoder.fit(y_set, h_set, batch_size=1000, epochs=30, validation_split=0.2)\n",
    "\n",
    "test_scores = decoder.evaluate(y_test, h_test, verbose=2)\n",
    "print(\"Test loss:\", test_scores[0])\n",
    "print(\"Test accuracy:\", test_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"estimator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bp1 (BatchNormalization)     (3, 50)                   200       \n",
      "_________________________________________________________________\n",
      "layer1 (Dense)               (3, 150)                  7650      \n",
      "_________________________________________________________________\n",
      "bp2 (BatchNormalization)     (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "bp3 (BatchNormalization)     (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer3 (Dense)               (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "pb4 (BatchNormalization)     (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer4 (Dense)               (3, 100)                  15100     \n",
      "=================================================================\n",
      "Total params: 70,050\n",
      "Trainable params: 69,050\n",
      "Non-trainable params: 1,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "estimator = keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp1\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer1\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp2\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer2\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp3\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer3\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"pb4\"),\n",
    "        layers.Dense(user_number, activation=\"relu\", name=\"layer4\"),\n",
    "    ],name = 'estimator'\n",
    ")\n",
    "# Call model on a test input\n",
    "y = tf.ones((3, code_length))\n",
    "x_hat = estimator(y)\n",
    "estimator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2000/2000 [==============================] - 32s 15ms/step - loss: 0.0652 - nmse_accuracy: -5.9160 - val_loss: 0.0097 - val_nmse_accuracy: -13.9134\n",
      "Epoch 2/30\n",
      "2000/2000 [==============================] - 34s 17ms/step - loss: 0.0092 - nmse_accuracy: -14.1203 - val_loss: 0.0079 - val_nmse_accuracy: -14.8773\n",
      "Epoch 3/30\n",
      "2000/2000 [==============================] - 33s 17ms/step - loss: 0.0079 - nmse_accuracy: -14.8092 - val_loss: 0.0072 - val_nmse_accuracy: -15.2688\n",
      "Epoch 4/30\n",
      "2000/2000 [==============================] - 26s 13ms/step - loss: 0.0074 - nmse_accuracy: -15.1167 - val_loss: 0.0069 - val_nmse_accuracy: -15.4451\n",
      "Epoch 5/30\n",
      "2000/2000 [==============================] - 25s 13ms/step - loss: 0.0071 - nmse_accuracy: -15.3180 - val_loss: 0.0068 - val_nmse_accuracy: -15.5173\n",
      "Epoch 6/30\n",
      "2000/2000 [==============================] - 24s 12ms/step - loss: 0.0069 - nmse_accuracy: -15.4425 - val_loss: 0.0066 - val_nmse_accuracy: -15.6298\n",
      "Epoch 7/30\n",
      "2000/2000 [==============================] - 24s 12ms/step - loss: 0.0068 - nmse_accuracy: -15.5330 - val_loss: 0.0065 - val_nmse_accuracy: -15.7435\n",
      "Epoch 8/30\n",
      "2000/2000 [==============================] - 24s 12ms/step - loss: 0.0067 - nmse_accuracy: -15.5838 - val_loss: 0.0065 - val_nmse_accuracy: -15.7643\n",
      "Epoch 9/30\n",
      "2000/2000 [==============================] - 24s 12ms/step - loss: 0.0066 - nmse_accuracy: -15.5978 - val_loss: 0.0064 - val_nmse_accuracy: -15.8077\n",
      "Epoch 10/30\n",
      "2000/2000 [==============================] - 24s 12ms/step - loss: 0.0066 - nmse_accuracy: -15.6682 - val_loss: 0.0063 - val_nmse_accuracy: -15.8655\n",
      "Epoch 11/30\n",
      "2000/2000 [==============================] - 24s 12ms/step - loss: 0.0065 - nmse_accuracy: -15.6832 - val_loss: 0.0063 - val_nmse_accuracy: -15.8909\n",
      "Epoch 12/30\n",
      "2000/2000 [==============================] - 24s 12ms/step - loss: 0.0065 - nmse_accuracy: -15.7197 - val_loss: 0.0063 - val_nmse_accuracy: -15.8958\n",
      "Epoch 13/30\n",
      "2000/2000 [==============================] - 26s 13ms/step - loss: 0.0065 - nmse_accuracy: -15.7245 - val_loss: 0.0063 - val_nmse_accuracy: -15.8822\n",
      "Epoch 14/30\n",
      "2000/2000 [==============================] - 24s 12ms/step - loss: 0.0064 - nmse_accuracy: -15.7561 - val_loss: 0.0062 - val_nmse_accuracy: -15.9226\n",
      "Epoch 15/30\n",
      "2000/2000 [==============================] - 25s 12ms/step - loss: 0.0064 - nmse_accuracy: -15.7709 - val_loss: 0.0062 - val_nmse_accuracy: -15.9577\n",
      "Epoch 16/30\n",
      "2000/2000 [==============================] - 28s 14ms/step - loss: 0.0064 - nmse_accuracy: -15.7839 - val_loss: 0.0063 - val_nmse_accuracy: -15.9040\n",
      "Epoch 17/30\n",
      "2000/2000 [==============================] - 24s 12ms/step - loss: 0.0064 - nmse_accuracy: -15.7718 - val_loss: 0.0061 - val_nmse_accuracy: -16.0020\n",
      "Epoch 18/30\n",
      "2000/2000 [==============================] - 25s 12ms/step - loss: 0.0064 - nmse_accuracy: -15.8151 - val_loss: 0.0062 - val_nmse_accuracy: -15.9920\n",
      "Epoch 19/30\n",
      "2000/2000 [==============================] - 25s 13ms/step - loss: 0.0064 - nmse_accuracy: -15.7983 - val_loss: 0.0062 - val_nmse_accuracy: -15.9825\n",
      "Epoch 20/30\n",
      "2000/2000 [==============================] - 25s 12ms/step - loss: 0.0063 - nmse_accuracy: -15.8350 - val_loss: 0.0061 - val_nmse_accuracy: -16.0038\n",
      "Epoch 21/30\n",
      "2000/2000 [==============================] - 25s 12ms/step - loss: 0.0063 - nmse_accuracy: -15.8124 - val_loss: 0.0062 - val_nmse_accuracy: -15.9781\n",
      "Epoch 22/30\n",
      "2000/2000 [==============================] - 29s 15ms/step - loss: 0.0063 - nmse_accuracy: -15.8438 - val_loss: 0.0061 - val_nmse_accuracy: -16.0244\n",
      "Epoch 23/30\n",
      "2000/2000 [==============================] - 33s 16ms/step - loss: 0.0063 - nmse_accuracy: -15.8226 - val_loss: 0.0061 - val_nmse_accuracy: -16.0095\n",
      "Epoch 24/30\n",
      "2000/2000 [==============================] - 25s 13ms/step - loss: 0.0063 - nmse_accuracy: -15.8502 - val_loss: 0.0061 - val_nmse_accuracy: -16.0386\n",
      "Epoch 25/30\n",
      "2000/2000 [==============================] - 30s 15ms/step - loss: 0.0063 - nmse_accuracy: -15.8401 - val_loss: 0.0061 - val_nmse_accuracy: -16.0577\n",
      "Epoch 26/30\n",
      "2000/2000 [==============================] - 32s 16ms/step - loss: 0.0063 - nmse_accuracy: -15.8653 - val_loss: 0.0061 - val_nmse_accuracy: -16.0596\n",
      "Epoch 27/30\n",
      "2000/2000 [==============================] - 29s 14ms/step - loss: 0.0063 - nmse_accuracy: -15.8515 - val_loss: 0.0060 - val_nmse_accuracy: -16.0904\n",
      "Epoch 28/30\n",
      "2000/2000 [==============================] - 32s 16ms/step - loss: 0.0063 - nmse_accuracy: -15.8820 - val_loss: 0.0060 - val_nmse_accuracy: -16.0897\n",
      "Epoch 29/30\n",
      "2000/2000 [==============================] - 26s 13ms/step - loss: 0.0062 - nmse_accuracy: -15.8764 - val_loss: 0.0060 - val_nmse_accuracy: -16.0945\n",
      "Epoch 30/30\n",
      "2000/2000 [==============================] - 25s 12ms/step - loss: 0.0062 - nmse_accuracy: -15.9061 - val_loss: 0.0060 - val_nmse_accuracy: -16.1173\n",
      "313/313 - 1s - loss: 0.0060 - nmse_accuracy: -1.5961e+01\n",
      "Test loss: 0.006015625316649675\n",
      "Test accuracy: -15.960895538330078\n"
     ]
    }
   ],
   "source": [
    "estimator.compile(\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    metrics=NMSE_Accuracy(),\n",
    ")\n",
    "\n",
    "history = estimator.fit(y_set, h_set, batch_size=1000, epochs=30, validation_split=0.2)\n",
    "\n",
    "test_scores = estimator.evaluate(y_test, h_test, verbose=2)\n",
    "print(\"Test loss:\", test_scores[0])\n",
    "print(\"Test accuracy:\", test_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"estimator_mini\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bp1 (BatchNormalization)     (3, 50)                   200       \n",
      "_________________________________________________________________\n",
      "layer1 (Dense)               (3, 100)                  5100      \n",
      "_________________________________________________________________\n",
      "bp2 (BatchNormalization)     (3, 100)                  400       \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (3, 100)                  10100     \n",
      "_________________________________________________________________\n",
      "bp3 (BatchNormalization)     (3, 100)                  400       \n",
      "_________________________________________________________________\n",
      "layer3 (Dense)               (3, 100)                  10100     \n",
      "_________________________________________________________________\n",
      "pb4 (BatchNormalization)     (3, 100)                  400       \n",
      "_________________________________________________________________\n",
      "layer4 (Dense)               (3, 100)                  10100     \n",
      "=================================================================\n",
      "Total params: 36,800\n",
      "Trainable params: 36,100\n",
      "Non-trainable params: 700\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "estimator_mini = keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp1\"),\n",
    "        layers.Dense(user_number, activation=\"relu\", name=\"layer1\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp2\"),\n",
    "        layers.Dense(user_number, activation=\"relu\", name=\"layer2\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp3\"),\n",
    "        layers.Dense(user_number, activation=\"relu\", name=\"layer3\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"pb4\"),\n",
    "        layers.Dense(user_number, activation=\"relu\", name=\"layer4\"),\n",
    "    ],name = 'estimator_mini'\n",
    ")\n",
    "# Call model on a test input\n",
    "y = tf.ones((3, code_length))\n",
    "x_hat = estimator_mini(y)\n",
    "estimator_mini.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2000/2000 [==============================] - 20s 9ms/step - loss: 0.0791 - nmse_accuracy: -4.8947 - val_loss: 0.0163 - val_nmse_accuracy: -11.5169\n",
      "Epoch 2/30\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.0150 - nmse_accuracy: -11.8580 - val_loss: 0.0132 - val_nmse_accuracy: -12.4799\n",
      "Epoch 3/30\n",
      "2000/2000 [==============================] - 18s 9ms/step - loss: 0.0132 - nmse_accuracy: -12.4430 - val_loss: 0.0123 - val_nmse_accuracy: -12.7854\n",
      "Epoch 4/30\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0125 - nmse_accuracy: -12.7141 - val_loss: 0.0121 - val_nmse_accuracy: -12.8745\n",
      "Epoch 5/30\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0123 - nmse_accuracy: -12.7674 - val_loss: 0.0120 - val_nmse_accuracy: -12.9188\n",
      "Epoch 6/30\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0122 - nmse_accuracy: -12.8157 - val_loss: 0.0118 - val_nmse_accuracy: -13.0076\n",
      "Epoch 7/30\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0120 - nmse_accuracy: -12.8715 - val_loss: 0.0117 - val_nmse_accuracy: -13.0221\n",
      "Epoch 8/30\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0120 - nmse_accuracy: -12.8877 - val_loss: 0.0116 - val_nmse_accuracy: -13.0726\n",
      "Epoch 9/30\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.0118 - nmse_accuracy: -12.9442 - val_loss: 0.0115 - val_nmse_accuracy: -13.1010\n",
      "Epoch 10/30\n",
      "2000/2000 [==============================] - 18s 9ms/step - loss: 0.0118 - nmse_accuracy: -12.9470 - val_loss: 0.0115 - val_nmse_accuracy: -13.1097\n",
      "Epoch 11/30\n",
      "2000/2000 [==============================] - 22s 11ms/step - loss: 0.0118 - nmse_accuracy: -12.9891 - val_loss: 0.0115 - val_nmse_accuracy: -13.1383\n",
      "Epoch 12/30\n",
      "2000/2000 [==============================] - 22s 11ms/step - loss: 0.0117 - nmse_accuracy: -12.9814 - val_loss: 0.0115 - val_nmse_accuracy: -13.1330\n",
      "Epoch 13/30\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.0117 - nmse_accuracy: -12.9702 - val_loss: 0.0115 - val_nmse_accuracy: -13.1412\n",
      "Epoch 14/30\n",
      "2000/2000 [==============================] - 21s 11ms/step - loss: 0.0117 - nmse_accuracy: -13.0047 - val_loss: 0.0114 - val_nmse_accuracy: -13.1448\n",
      "Epoch 15/30\n",
      "2000/2000 [==============================] - 17s 8ms/step - loss: 0.0117 - nmse_accuracy: -12.9883 - val_loss: 0.0114 - val_nmse_accuracy: -13.1645\n",
      "Epoch 16/30\n",
      "2000/2000 [==============================] - 17s 9ms/step - loss: 0.0117 - nmse_accuracy: -13.0215 - val_loss: 0.0114 - val_nmse_accuracy: -13.1654\n",
      "Epoch 17/30\n",
      "2000/2000 [==============================] - 18s 9ms/step - loss: 0.0117 - nmse_accuracy: -13.0359 - val_loss: 0.0114 - val_nmse_accuracy: -13.1522\n",
      "Epoch 18/30\n",
      "2000/2000 [==============================] - 17s 9ms/step - loss: 0.0117 - nmse_accuracy: -13.0508 - val_loss: 0.0114 - val_nmse_accuracy: -13.1647\n",
      "Epoch 19/30\n",
      "2000/2000 [==============================] - 17s 9ms/step - loss: 0.0116 - nmse_accuracy: -inf - val_loss: 0.0112 - val_nmse_accuracy: -13.2252\n",
      "Epoch 20/30\n",
      "2000/2000 [==============================] - 17s 8ms/step - loss: 0.0115 - nmse_accuracy: -13.0632 - val_loss: 0.0113 - val_nmse_accuracy: -13.2160\n",
      "Epoch 21/30\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0115 - nmse_accuracy: -13.1428 - val_loss: 0.0112 - val_nmse_accuracy: -13.2469\n",
      "Epoch 22/30\n",
      "2000/2000 [==============================] - 18s 9ms/step - loss: 0.0115 - nmse_accuracy: -13.0685 - val_loss: 0.0112 - val_nmse_accuracy: -13.2541\n",
      "Epoch 23/30\n",
      "2000/2000 [==============================] - 18s 9ms/step - loss: 0.0115 - nmse_accuracy: -13.0997 - val_loss: 0.0112 - val_nmse_accuracy: -13.2460\n",
      "Epoch 24/30\n",
      "2000/2000 [==============================] - 18s 9ms/step - loss: 0.0115 - nmse_accuracy: -13.0861 - val_loss: 0.0112 - val_nmse_accuracy: -13.2529\n",
      "Epoch 25/30\n",
      "2000/2000 [==============================] - 19s 9ms/step - loss: 0.0115 - nmse_accuracy: -13.1220 - val_loss: 0.0112 - val_nmse_accuracy: -13.2517\n",
      "Epoch 26/30\n",
      "2000/2000 [==============================] - 18s 9ms/step - loss: 0.0114 - nmse_accuracy: -13.1047 - val_loss: 0.0112 - val_nmse_accuracy: -13.2532\n",
      "Epoch 27/30\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0114 - nmse_accuracy: -13.1117 - val_loss: 0.0111 - val_nmse_accuracy: -13.2716\n",
      "Epoch 28/30\n",
      "2000/2000 [==============================] - 17s 8ms/step - loss: 0.0115 - nmse_accuracy: -13.0684 - val_loss: 0.0111 - val_nmse_accuracy: -13.2731\n",
      "Epoch 29/30\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0114 - nmse_accuracy: -13.0681 - val_loss: 0.0111 - val_nmse_accuracy: -13.2685\n",
      "Epoch 30/30\n",
      "2000/2000 [==============================] - 19s 9ms/step - loss: 0.0114 - nmse_accuracy: -13.1001 - val_loss: 0.0111 - val_nmse_accuracy: -13.2724\n",
      "313/313 - 1s - loss: 0.0110 - nmse_accuracy: -1.3152e+01\n",
      "Test loss: 0.011029518209397793\n",
      "Test accuracy: -13.15235710144043\n"
     ]
    }
   ],
   "source": [
    "estimator_mini.compile(\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    metrics=NMSE_Accuracy(),\n",
    ")\n",
    "\n",
    "history = estimator_mini.fit(y_set, h_set, batch_size=1000, epochs=30, validation_split=0.2)\n",
    "\n",
    "test_scores = estimator_mini.evaluate(y_test, h_test, verbose=2)\n",
    "print(\"Test loss:\", test_scores[0])\n",
    "print(\"Test accuracy:\", test_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"estimator_big\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bp1 (BatchNormalization)     (3, 50)                   200       \n",
      "_________________________________________________________________\n",
      "layer1 (Dense)               (3, 200)                  10200     \n",
      "_________________________________________________________________\n",
      "bp2 (BatchNormalization)     (3, 200)                  800       \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (3, 200)                  40200     \n",
      "_________________________________________________________________\n",
      "bp3 (BatchNormalization)     (3, 200)                  800       \n",
      "_________________________________________________________________\n",
      "layer3 (Dense)               (3, 200)                  40200     \n",
      "_________________________________________________________________\n",
      "pb4 (BatchNormalization)     (3, 200)                  800       \n",
      "_________________________________________________________________\n",
      "layer4 (Dense)               (3, 100)                  20100     \n",
      "=================================================================\n",
      "Total params: 113,300\n",
      "Trainable params: 112,000\n",
      "Non-trainable params: 1,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "estimator_big = keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp1\"),\n",
    "        layers.Dense(user_number*2, activation=\"relu\", name=\"layer1\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp2\"),\n",
    "        layers.Dense(user_number*2, activation=\"relu\", name=\"layer2\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp3\"),\n",
    "        layers.Dense(user_number*2, activation=\"relu\", name=\"layer3\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"pb4\"),\n",
    "        layers.Dense(user_number, activation=\"relu\", name=\"layer4\"),\n",
    "    ],name = 'estimator_big'\n",
    ")\n",
    "# Call model on a test input\n",
    "y = tf.ones((3, code_length))\n",
    "x_hat = estimator_big(y)\n",
    "estimator_big.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2000/2000 [==============================] - 35s 17ms/step - loss: 0.0587 - nmse_accuracy: -6.4189 - val_loss: 0.0082 - val_nmse_accuracy: -14.6806\n",
      "Epoch 2/30\n",
      "2000/2000 [==============================] - 31s 16ms/step - loss: 0.0076 - nmse_accuracy: -14.9916 - val_loss: 0.0062 - val_nmse_accuracy: -15.9025\n",
      "Epoch 3/30\n",
      "2000/2000 [==============================] - 33s 16ms/step - loss: 0.0061 - nmse_accuracy: -15.9682 - val_loss: 0.0055 - val_nmse_accuracy: -16.4617\n",
      "Epoch 4/30\n",
      "2000/2000 [==============================] - 31s 16ms/step - loss: 0.0056 - nmse_accuracy: -16.3830 - val_loss: 0.0052 - val_nmse_accuracy: -16.7763\n",
      "Epoch 5/30\n",
      "2000/2000 [==============================] - 36s 18ms/step - loss: 0.0052 - nmse_accuracy: -16.6506 - val_loss: 0.0049 - val_nmse_accuracy: -16.9725\n",
      "Epoch 6/30\n",
      "2000/2000 [==============================] - 32s 16ms/step - loss: 0.0050 - nmse_accuracy: -16.8192 - val_loss: 0.0048 - val_nmse_accuracy: -17.1275\n",
      "Epoch 7/30\n",
      "2000/2000 [==============================] - 32s 16ms/step - loss: 0.0049 - nmse_accuracy: -17.0037 - val_loss: 0.0046 - val_nmse_accuracy: -17.3204\n",
      "Epoch 8/30\n",
      "2000/2000 [==============================] - 33s 16ms/step - loss: 0.0048 - nmse_accuracy: -17.1173 - val_loss: 0.0046 - val_nmse_accuracy: -17.3115\n",
      "Epoch 9/30\n",
      "2000/2000 [==============================] - 39s 19ms/step - loss: 0.0047 - nmse_accuracy: -17.1690 - val_loss: 0.0044 - val_nmse_accuracy: -17.4708\n",
      "Epoch 10/30\n",
      "2000/2000 [==============================] - 42s 21ms/step - loss: 0.0046 - nmse_accuracy: -17.2813 - val_loss: 0.0044 - val_nmse_accuracy: -17.5456\n",
      "Epoch 11/30\n",
      "2000/2000 [==============================] - 33s 17ms/step - loss: 0.0045 - nmse_accuracy: -17.3423 - val_loss: 0.0044 - val_nmse_accuracy: -17.5542\n",
      "Epoch 12/30\n",
      "2000/2000 [==============================] - 33s 17ms/step - loss: 0.0045 - nmse_accuracy: -17.3925 - val_loss: 0.0043 - val_nmse_accuracy: -17.6591\n",
      "Epoch 13/30\n",
      "2000/2000 [==============================] - 33s 17ms/step - loss: 0.0045 - nmse_accuracy: -inf - val_loss: 0.0042 - val_nmse_accuracy: -17.6936\n",
      "Epoch 14/30\n",
      "2000/2000 [==============================] - 39s 19ms/step - loss: 0.0044 - nmse_accuracy: -17.4377 - val_loss: 0.0042 - val_nmse_accuracy: -17.6962\n",
      "Epoch 15/30\n",
      "2000/2000 [==============================] - 35s 17ms/step - loss: 0.0044 - nmse_accuracy: -17.4955 - val_loss: 0.0042 - val_nmse_accuracy: -17.7573\n",
      "Epoch 16/30\n",
      "2000/2000 [==============================] - 33s 17ms/step - loss: 0.0043 - nmse_accuracy: -17.5302 - val_loss: 0.0041 - val_nmse_accuracy: -17.8190\n",
      "Epoch 17/30\n",
      "2000/2000 [==============================] - 34s 17ms/step - loss: 0.0043 - nmse_accuracy: -17.5433 - val_loss: 0.0042 - val_nmse_accuracy: -17.7952\n",
      "Epoch 18/30\n",
      "2000/2000 [==============================] - 35s 18ms/step - loss: 0.0043 - nmse_accuracy: -17.5589 - val_loss: 0.0042 - val_nmse_accuracy: -17.7469\n",
      "Epoch 19/30\n",
      "2000/2000 [==============================] - 46s 23ms/step - loss: 0.0043 - nmse_accuracy: -17.5950 - val_loss: 0.0041 - val_nmse_accuracy: -17.8226\n",
      "Epoch 20/30\n",
      "2000/2000 [==============================] - 37s 18ms/step - loss: 0.0043 - nmse_accuracy: -17.5711 - val_loss: 0.0041 - val_nmse_accuracy: -17.9094\n",
      "Epoch 21/30\n",
      "2000/2000 [==============================] - 42s 21ms/step - loss: 0.0043 - nmse_accuracy: -17.5944 - val_loss: 0.0041 - val_nmse_accuracy: -17.9031\n",
      "Epoch 22/30\n",
      "2000/2000 [==============================] - 37s 18ms/step - loss: 0.0043 - nmse_accuracy: -17.6353 - val_loss: 0.0041 - val_nmse_accuracy: -17.8800\n",
      "Epoch 23/30\n",
      "2000/2000 [==============================] - 35s 18ms/step - loss: 0.0042 - nmse_accuracy: -17.6357 - val_loss: 0.0041 - val_nmse_accuracy: -17.8941\n",
      "Epoch 24/30\n",
      "2000/2000 [==============================] - 35s 17ms/step - loss: 0.0042 - nmse_accuracy: -17.6812 - val_loss: 0.0040 - val_nmse_accuracy: -17.9432\n",
      "Epoch 25/30\n",
      "2000/2000 [==============================] - 36s 18ms/step - loss: 0.0042 - nmse_accuracy: -17.7039 - val_loss: 0.0040 - val_nmse_accuracy: -17.9211\n",
      "Epoch 26/30\n",
      "2000/2000 [==============================] - 35s 17ms/step - loss: 0.0042 - nmse_accuracy: -17.6943 - val_loss: 0.0040 - val_nmse_accuracy: -17.9714\n",
      "Epoch 27/30\n",
      "2000/2000 [==============================] - 35s 17ms/step - loss: 0.0042 - nmse_accuracy: -17.6797 - val_loss: 0.0040 - val_nmse_accuracy: -17.9668\n",
      "Epoch 28/30\n",
      "2000/2000 [==============================] - 37s 19ms/step - loss: 0.0042 - nmse_accuracy: -17.7242 - val_loss: 0.0040 - val_nmse_accuracy: -17.9721\n",
      "Epoch 29/30\n",
      "2000/2000 [==============================] - 36s 18ms/step - loss: 0.0042 - nmse_accuracy: -17.7293 - val_loss: 0.0040 - val_nmse_accuracy: -18.0022\n",
      "Epoch 30/30\n",
      "2000/2000 [==============================] - 38s 19ms/step - loss: 0.0042 - nmse_accuracy: -17.7408 - val_loss: 0.0040 - val_nmse_accuracy: -18.0234\n",
      "313/313 - 1s - loss: 0.0040 - nmse_accuracy: -1.7854e+01\n",
      "Test loss: 0.00398174487054348\n",
      "Test accuracy: -17.85357666015625\n"
     ]
    }
   ],
   "source": [
    "estimator_big.compile(\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    metrics=NMSE_Accuracy(),\n",
    ")\n",
    "\n",
    "history = estimator_big.fit(y_set, h_set, batch_size=1000, epochs=30, validation_split=0.2)\n",
    "\n",
    "test_scores = estimator_big.evaluate(y_test, h_test, verbose=2)\n",
    "print(\"Test loss:\", test_scores[0])\n",
    "print(\"Test accuracy:\", test_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bp1 (BatchNormalization)     (3, 50)                   200       \n",
      "_________________________________________________________________\n",
      "layer1 (Dense)               (3, 150)                  7650      \n",
      "_________________________________________________________________\n",
      "bp2 (BatchNormalization)     (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "bp3 (BatchNormalization)     (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer3 (Dense)               (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "pb4 (BatchNormalization)     (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer4 (Dense)               (3, 100)                  15100     \n",
      "_________________________________________________________________\n",
      "bp1_2 (BatchNormalization)   (3, 100)                  400       \n",
      "_________________________________________________________________\n",
      "layer1_2 (Dense)             (3, 150)                  15150     \n",
      "_________________________________________________________________\n",
      "bp2_2 (BatchNormalization)   (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer2_2 (Dense)             (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "bp3_2 (BatchNormalization)   (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer3_2 (Dense)             (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "pb4_2 (BatchNormalization)   (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer4_2 (Dense)             (3, 100)                  15100     \n",
      "_________________________________________________________________\n",
      "bp1_3 (BatchNormalization)   (3, 100)                  400       \n",
      "_________________________________________________________________\n",
      "layer1_3 (Dense)             (3, 150)                  15150     \n",
      "_________________________________________________________________\n",
      "bp2_3 (BatchNormalization)   (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer2_3 (Dense)             (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "bp3_3 (BatchNormalization)   (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer3_3 (Dense)             (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "pb4_3 (BatchNormalization)   (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer4_3 (Dense)             (3, 100)                  15100     \n",
      "_________________________________________________________________\n",
      "bp1_4 (BatchNormalization)   (3, 100)                  400       \n",
      "_________________________________________________________________\n",
      "layer1_4 (Dense)             (3, 150)                  15150     \n",
      "_________________________________________________________________\n",
      "bp2_4 (BatchNormalization)   (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer2_4 (Dense)             (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "bp3_4 (BatchNormalization)   (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer3_4 (Dense)             (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "pb4_4 (BatchNormalization)   (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer4_4 (Dense)             (3, 100)                  15100     \n",
      "_________________________________________________________________\n",
      "bp1_5 (BatchNormalization)   (3, 100)                  400       \n",
      "_________________________________________________________________\n",
      "layer1_5 (Dense)             (3, 150)                  15150     \n",
      "_________________________________________________________________\n",
      "bp2_5 (BatchNormalization)   (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer2_5 (Dense)             (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "bp3_5 (BatchNormalization)   (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer3_5 (Dense)             (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "pb4_5 (BatchNormalization)   (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer4_5 (Dense)             (3, 100)                  15100     \n",
      "=================================================================\n",
      "Total params: 381,050\n",
      "Trainable params: 375,650\n",
      "Non-trainable params: 5,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_norm_loss = keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp1\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer1\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp2\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer2\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp3\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer3\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"pb4\"),\n",
    "        layers.Dense(user_number, activation=\"relu\", name=\"layer4\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp1_2\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer1_2\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp2_2\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer2_2\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp3_2\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer3_2\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"pb4_2\"),\n",
    "        layers.Dense(user_number, activation=\"sigmoid\", name=\"layer4_2\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp1_3\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer1_3\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp2_3\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer2_3\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp3_3\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer3_3\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"pb4_3\"),\n",
    "        layers.Dense(user_number, activation=\"relu\", name=\"layer4_3\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp1_4\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer1_4\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp2_4\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer2_4\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp3_4\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer3_4\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"pb4_4\"),\n",
    "        layers.Dense(user_number, activation=\"sigmoid\", name=\"layer4_4\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp1_5\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer1_5\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp2_5\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer2_5\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp3_5\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer3_5\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"pb4_5\"),\n",
    "        layers.Dense(user_number, activation=\"relu\", name=\"layer4_5\"),\n",
    "    ],name = 'decoder'\n",
    ")\n",
    "# Call model on a test input\n",
    "y = tf.ones((3, code_length))\n",
    "x_hat = decoder_norm_loss(y)\n",
    "decoder_norm_loss.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2000/2000 [==============================] - 151s 71ms/step - loss: 0.1680 - nmse_accuracy: -0.8516 - val_loss: 0.1305 - val_nmse_accuracy: -1.9805\n",
      "Epoch 2/30\n",
      "2000/2000 [==============================] - 124s 62ms/step - loss: 0.1112 - nmse_accuracy: -2.7178 - val_loss: 0.1047 - val_nmse_accuracy: -3.0463\n",
      "Epoch 3/30\n",
      "2000/2000 [==============================] - 133s 66ms/step - loss: 0.1001 - nmse_accuracy: -3.2248 - val_loss: 0.0973 - val_nmse_accuracy: -3.3773\n",
      "Epoch 4/30\n",
      "2000/2000 [==============================] - 122s 61ms/step - loss: 0.0903 - nmse_accuracy: -3.7225 - val_loss: 0.0873 - val_nmse_accuracy: -3.9096\n",
      "Epoch 5/30\n",
      "2000/2000 [==============================] - 132s 66ms/step - loss: 0.0823 - nmse_accuracy: -4.1741 - val_loss: 0.0825 - val_nmse_accuracy: -4.1569\n",
      "Epoch 6/30\n",
      "2000/2000 [==============================] - 125s 62ms/step - loss: 0.0729 - nmse_accuracy: -4.7359 - val_loss: 0.0692 - val_nmse_accuracy: -5.0183\n",
      "Epoch 7/30\n",
      "2000/2000 [==============================] - 132s 66ms/step - loss: 0.0635 - nmse_accuracy: -5.4028 - val_loss: 0.0671 - val_nmse_accuracy: -5.0516\n",
      "Epoch 8/30\n",
      "2000/2000 [==============================] - 126s 63ms/step - loss: 0.0571 - nmse_accuracy: -5.9129 - val_loss: 0.0735 - val_nmse_accuracy: -4.6480\n",
      "Epoch 9/30\n",
      "2000/2000 [==============================] - 126s 63ms/step - loss: 0.0528 - nmse_accuracy: -6.2614 - val_loss: 0.0531 - val_nmse_accuracy: -6.2357\n",
      "Epoch 10/30\n",
      "2000/2000 [==============================] - 128s 64ms/step - loss: 0.0470 - nmse_accuracy: -6.8117 - val_loss: 0.0501 - val_nmse_accuracy: -6.4766\n",
      "Epoch 11/30\n",
      "2000/2000 [==============================] - 130s 65ms/step - loss: 0.0424 - nmse_accuracy: -7.2826 - val_loss: 0.0444 - val_nmse_accuracy: -7.0466\n",
      "Epoch 12/30\n",
      "2000/2000 [==============================] - 128s 64ms/step - loss: 0.0399 - nmse_accuracy: -7.5668 - val_loss: 0.0433 - val_nmse_accuracy: -7.1645\n",
      "Epoch 13/30\n",
      "2000/2000 [==============================] - 126s 63ms/step - loss: 0.0379 - nmse_accuracy: -7.7740 - val_loss: 0.0403 - val_nmse_accuracy: -7.5529\n",
      "Epoch 14/30\n",
      "2000/2000 [==============================] - 126s 63ms/step - loss: 0.0362 - nmse_accuracy: -8.0215 - val_loss: 0.0422 - val_nmse_accuracy: -7.2385\n",
      "Epoch 15/30\n",
      "2000/2000 [==============================] - 126s 63ms/step - loss: 0.0352 - nmse_accuracy: -8.1323 - val_loss: 0.0395 - val_nmse_accuracy: -7.5406\n",
      "Epoch 16/30\n",
      "2000/2000 [==============================] - 126s 63ms/step - loss: 0.0336 - nmse_accuracy: -8.3295 - val_loss: 0.0426 - val_nmse_accuracy: -7.0891\n",
      "Epoch 17/30\n",
      "2000/2000 [==============================] - 136s 68ms/step - loss: 0.0322 - nmse_accuracy: -8.5418 - val_loss: 0.0356 - val_nmse_accuracy: -8.0179\n",
      "Epoch 18/30\n",
      "2000/2000 [==============================] - 118s 59ms/step - loss: 0.0315 - nmse_accuracy: -8.6615 - val_loss: 11.2653 - val_nmse_accuracy: 13.2424\n",
      "Epoch 19/30\n",
      "1434/2000 [====================>.........] - ETA: 37s - loss: 0.0310 - nmse_accuracy: -8.6869"
     ]
    }
   ],
   "source": [
    "decoder_norm_loss.compile(\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    metrics=NMSE_Accuracy(),\n",
    ")\n",
    "\n",
    "history = decoder_norm_loss.fit(y_set, h_set, batch_size=1000, epochs=30, validation_split=0.2)\n",
    "\n",
    "test_scores = decoder_norm_loss.evaluate(y_test, h_test, verbose=2)\n",
    "print(\"Test loss:\", test_scores[0])\n",
    "print(\"Test accuracy:\", test_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
