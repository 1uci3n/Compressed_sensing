{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "import data_tool as dt\n",
    "import keras_tool as kt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "%rm -rf ./temp10/logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_number = 100\n",
    "code_length = 50\n",
    "epoch_number = 30\n",
    "batch_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signature matrix:\n",
      " [[-1  0 -1 ... -1  0  0]\n",
      " [ 0  1  0 ...  0  0  0]\n",
      " [ 0  1  0 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0 -1 ...  0  0 -1]\n",
      " [ 0 -1 -1 ...  0 -1  0]\n",
      " [ 0  0  0 ...  0 -1 -1]]\n",
      "signale power per bit:\n",
      " 5.11426\n"
     ]
    }
   ],
   "source": [
    "signature_matrix = dt.get_random_triad_signature_matrix_0_1_inverse1(user_number, code_length)\n",
    "y_set_10dB, x_set_10dB, h_set_10dB, y_set_out_10dB = dt.get_dataset_with_noise(1000000, signature_matrix, 10, is_fading=1)\n",
    "y_set_10dB = y_set_10dB.astype(\"float32\")\n",
    "x_set_10dB = x_set_10dB.astype(\"float32\")\n",
    "h_set_10dB = h_set_10dB.astype(\"float32\")\n",
    "y_set_out_10dB = y_set_out_10dB.astype(\"float32\")\n",
    "y_test_10dB, x_test_10dB, h_test_10dB, y_test_out_10dB = dt.get_dataset_with_noise(10000, signature_matrix, 10, is_fading=1)\n",
    "y_test_10dB = y_test_10dB.astype(\"float32\")\n",
    "x_test_10dB = x_test_10dB.astype(\"float32\")\n",
    "h_test_10dB = h_test_10dB.astype(\"float32\")\n",
    "y_test_out_10dB = y_test_out_10dB.astype(\"float32\")\n",
    "print(\"signature matrix:\\n\", signature_matrix)\n",
    "print(\"signale power per bit:\\n\", dt.test_power_of_signature_matrix(signature_matrix, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"estimator_simple\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bp1 (BatchNormalization)     (3, 50)                   200       \n",
      "_________________________________________________________________\n",
      "layer1 (Dense)               (3, 150)                  7650      \n",
      "_________________________________________________________________\n",
      "bp2 (BatchNormalization)     (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer4 (Dense)               (3, 100)                  15100     \n",
      "=================================================================\n",
      "Total params: 23,550\n",
      "Trainable params: 23,150\n",
      "Non-trainable params: 400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "estimator_simple = keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp1\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer1\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp2\"),\n",
    "        layers.Dense(user_number, activation=\"relu\", name=\"layer4\"),\n",
    "    ],name = 'estimator_simple'\n",
    ")\n",
    "# Call model on a test input\n",
    "y = tf.ones((3, code_length))\n",
    "x_hat = estimator_simple(y)\n",
    "estimator_simple.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1000/1000 [==============================] - 8s 7ms/step - loss: 0.1091 - nmse_accuracy: -3.3328 - bit_error_ratio: 0.2056 - val_loss: 0.0367 - val_nmse_accuracy: -7.4824 - val_bit_error_ratio: 0.1061\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0334 - nmse_accuracy: -7.9890 - bit_error_ratio: 0.1010 - val_loss: 0.0270 - val_nmse_accuracy: -8.7712 - val_bit_error_ratio: 0.0982\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0264 - nmse_accuracy: -8.9943 - bit_error_ratio: 0.0962 - val_loss: 0.0244 - val_nmse_accuracy: -9.2071 - val_bit_error_ratio: 0.0938\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0243 - nmse_accuracy: -9.3823 - bit_error_ratio: 0.0941 - val_loss: 0.0233 - val_nmse_accuracy: -9.3869 - val_bit_error_ratio: 0.0929\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0234 - nmse_accuracy: -9.5172 - bit_error_ratio: 0.0920 - val_loss: 0.0228 - val_nmse_accuracy: -9.4823 - val_bit_error_ratio: 0.0917\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0231 - nmse_accuracy: -9.5933 - bit_error_ratio: 0.0902 - val_loss: 0.0227 - val_nmse_accuracy: -9.5095 - val_bit_error_ratio: 0.0902\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0229 - nmse_accuracy: -9.5943 - bit_error_ratio: 0.0888 - val_loss: 0.0226 - val_nmse_accuracy: -9.5329 - val_bit_error_ratio: 0.0866\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0229 - nmse_accuracy: -9.6123 - bit_error_ratio: 0.0879 - val_loss: 0.0225 - val_nmse_accuracy: -9.5451 - val_bit_error_ratio: 0.0878\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0228 - nmse_accuracy: -9.6106 - bit_error_ratio: 0.0873 - val_loss: 0.0225 - val_nmse_accuracy: -9.5479 - val_bit_error_ratio: 0.0869\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0228 - nmse_accuracy: -9.6310 - bit_error_ratio: 0.0868 - val_loss: 0.0225 - val_nmse_accuracy: -9.5530 - val_bit_error_ratio: 0.0857\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0227 - nmse_accuracy: -9.6415 - bit_error_ratio: 0.0865 - val_loss: 0.0224 - val_nmse_accuracy: -9.5669 - val_bit_error_ratio: 0.0867\n",
      "Epoch 12/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0227 - nmse_accuracy: -9.6729 - bit_error_ratio: 0.0862 - val_loss: 0.0225 - val_nmse_accuracy: -9.5684 - val_bit_error_ratio: 0.0846\n",
      "Epoch 13/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0227 - nmse_accuracy: -9.6921 - bit_error_ratio: 0.0860 - val_loss: 0.0224 - val_nmse_accuracy: -9.5738 - val_bit_error_ratio: 0.0854\n",
      "Epoch 14/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0227 - nmse_accuracy: -9.6557 - bit_error_ratio: 0.0858 - val_loss: 0.0224 - val_nmse_accuracy: -9.5734 - val_bit_error_ratio: 0.0858\n",
      "Epoch 15/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0227 - nmse_accuracy: -9.6556 - bit_error_ratio: 0.0858 - val_loss: 0.0224 - val_nmse_accuracy: -9.5865 - val_bit_error_ratio: 0.0845\n",
      "Epoch 16/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0227 - nmse_accuracy: -9.6550 - bit_error_ratio: 0.0857 - val_loss: 0.0224 - val_nmse_accuracy: -9.5773 - val_bit_error_ratio: 0.0861\n",
      "Epoch 17/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0226 - nmse_accuracy: -9.6838 - bit_error_ratio: 0.0857 - val_loss: 0.0224 - val_nmse_accuracy: -9.5803 - val_bit_error_ratio: 0.0845\n",
      "Epoch 18/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0226 - nmse_accuracy: -9.6652 - bit_error_ratio: 0.0856 - val_loss: 0.0223 - val_nmse_accuracy: -9.5913 - val_bit_error_ratio: 0.0845\n",
      "Epoch 19/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0226 - nmse_accuracy: -inf - bit_error_ratio: 0.0855 - val_loss: 0.0223 - val_nmse_accuracy: -9.5876 - val_bit_error_ratio: 0.0846\n",
      "Epoch 20/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0226 - nmse_accuracy: -9.6711 - bit_error_ratio: 0.0854 - val_loss: 0.0224 - val_nmse_accuracy: -9.5858 - val_bit_error_ratio: 0.0838\n",
      "Epoch 21/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0226 - nmse_accuracy: -9.6334 - bit_error_ratio: 0.0854 - val_loss: 0.0223 - val_nmse_accuracy: -9.5982 - val_bit_error_ratio: 0.0845\n",
      "Epoch 22/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0226 - nmse_accuracy: -9.7041 - bit_error_ratio: 0.0854 - val_loss: 0.0223 - val_nmse_accuracy: -9.5959 - val_bit_error_ratio: 0.0839\n",
      "Epoch 23/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0226 - nmse_accuracy: -9.6949 - bit_error_ratio: 0.0854 - val_loss: 0.0223 - val_nmse_accuracy: -9.6039 - val_bit_error_ratio: 0.0833\n",
      "Epoch 24/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0226 - nmse_accuracy: -9.6776 - bit_error_ratio: 0.0853 - val_loss: 0.0223 - val_nmse_accuracy: -9.6003 - val_bit_error_ratio: 0.0840\n",
      "Epoch 25/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0226 - nmse_accuracy: -9.6481 - bit_error_ratio: 0.0853 - val_loss: 0.0223 - val_nmse_accuracy: -9.6047 - val_bit_error_ratio: 0.0830\n",
      "Epoch 26/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0226 - nmse_accuracy: -9.7021 - bit_error_ratio: 0.0852 - val_loss: 0.0222 - val_nmse_accuracy: -9.6069 - val_bit_error_ratio: 0.0847\n",
      "Epoch 27/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0226 - nmse_accuracy: -9.6508 - bit_error_ratio: 0.0854 - val_loss: 0.0223 - val_nmse_accuracy: -9.6030 - val_bit_error_ratio: 0.0836\n",
      "Epoch 28/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0226 - nmse_accuracy: -9.6863 - bit_error_ratio: 0.0853 - val_loss: 0.0223 - val_nmse_accuracy: -9.6031 - val_bit_error_ratio: 0.0834\n",
      "Epoch 29/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0226 - nmse_accuracy: -9.6550 - bit_error_ratio: 0.0852 - val_loss: 0.0222 - val_nmse_accuracy: -9.6090 - val_bit_error_ratio: 0.0850\n",
      "Epoch 30/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0225 - nmse_accuracy: -9.7415 - bit_error_ratio: 0.0852 - val_loss: 0.0222 - val_nmse_accuracy: -9.6150 - val_bit_error_ratio: 0.0847\n"
     ]
    }
   ],
   "source": [
    "estimator_simple.compile(\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    metrics=[kt.NMSE_Accuracy(), kt.Bit_Error_Ratio_Threshold_0_01()],\n",
    ")\n",
    "\n",
    "log_dir=\"./temp10/logs/fit/\" + datetime.datetime.now().strftime(\"estimator_simple_%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "history = estimator_simple.fit(y_set_10dB, h_set_10dB, batch_size=1000, epochs=30, validation_data=(y_test_10dB, h_test_10dB), callbacks=[tensorboard_callback])\n",
    "\n",
    "# test_scores = estimator_simple.evaluate(y_test, h_test, verbose=2)\n",
    "# print(\"Test loss:\", test_scores[0])\n",
    "# print(\"Test accuracy:\", test_scores[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"estimator_middel\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bp1 (BatchNormalization)     (3, 50)                   200       \n",
      "_________________________________________________________________\n",
      "layer1 (Dense)               (3, 150)                  7650      \n",
      "_________________________________________________________________\n",
      "bp2 (BatchNormalization)     (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "bp3 (BatchNormalization)     (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer3 (Dense)               (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "pb4 (BatchNormalization)     (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer4 (Dense)               (3, 100)                  15100     \n",
      "=================================================================\n",
      "Total params: 70,050\n",
      "Trainable params: 69,050\n",
      "Non-trainable params: 1,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "estimator_middel = keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp1\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer1\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp2\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer2\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp3\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer3\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"pb4\"),\n",
    "        layers.Dense(user_number, activation=\"relu\", name=\"layer4\"),\n",
    "    ],name = 'estimator_middel'\n",
    ")\n",
    "# Call model on a test input\n",
    "y = tf.ones((3, code_length))\n",
    "x_hat = estimator_middel(y)\n",
    "estimator_middel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1000/1000 [==============================] - 12s 11ms/step - loss: 0.1054 - nmse_accuracy: -3.3568 - bit_error_ratio: 0.2220 - val_loss: 0.0267 - val_nmse_accuracy: -8.8274 - val_bit_error_ratio: 0.0814\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0239 - nmse_accuracy: -9.5277 - bit_error_ratio: 0.0802 - val_loss: 0.0206 - val_nmse_accuracy: -9.9275 - val_bit_error_ratio: 0.0744\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0203 - nmse_accuracy: -10.1003 - bit_error_ratio: 0.0751 - val_loss: 0.0194 - val_nmse_accuracy: -10.1824 - val_bit_error_ratio: 0.0769\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0194 - nmse_accuracy: -inf - bit_error_ratio: 0.0744 - val_loss: 0.0187 - val_nmse_accuracy: -10.3276 - val_bit_error_ratio: 0.0729\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0188 - nmse_accuracy: -10.4273 - bit_error_ratio: 0.0743 - val_loss: 0.0183 - val_nmse_accuracy: -10.4173 - val_bit_error_ratio: 0.0738\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0184 - nmse_accuracy: -10.4999 - bit_error_ratio: 0.0743 - val_loss: 0.0179 - val_nmse_accuracy: -10.5002 - val_bit_error_ratio: 0.0715\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0181 - nmse_accuracy: -10.5691 - bit_error_ratio: 0.0744 - val_loss: 0.0178 - val_nmse_accuracy: -10.5220 - val_bit_error_ratio: 0.0751\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0179 - nmse_accuracy: -10.6129 - bit_error_ratio: 0.0746 - val_loss: 0.0177 - val_nmse_accuracy: -10.5518 - val_bit_error_ratio: 0.0757\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0178 - nmse_accuracy: -10.6671 - bit_error_ratio: 0.0746 - val_loss: 0.0174 - val_nmse_accuracy: -10.6180 - val_bit_error_ratio: 0.0742\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0176 - nmse_accuracy: -10.6733 - bit_error_ratio: 0.0747 - val_loss: 0.0174 - val_nmse_accuracy: -10.6261 - val_bit_error_ratio: 0.0759\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0175 - nmse_accuracy: -10.7672 - bit_error_ratio: 0.0748 - val_loss: 0.0172 - val_nmse_accuracy: -10.6559 - val_bit_error_ratio: 0.0752\n",
      "Epoch 12/30\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0174 - nmse_accuracy: -10.7545 - bit_error_ratio: 0.0748 - val_loss: 0.0171 - val_nmse_accuracy: -10.6930 - val_bit_error_ratio: 0.0768\n",
      "Epoch 13/30\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0173 - nmse_accuracy: -10.7373 - bit_error_ratio: 0.0749 - val_loss: 0.0170 - val_nmse_accuracy: -10.7335 - val_bit_error_ratio: 0.0728\n",
      "Epoch 14/30\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0172 - nmse_accuracy: -10.8459 - bit_error_ratio: 0.0748 - val_loss: 0.0170 - val_nmse_accuracy: -10.7199 - val_bit_error_ratio: 0.0739\n",
      "Epoch 15/30\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0171 - nmse_accuracy: -10.7815 - bit_error_ratio: 0.0749 - val_loss: 0.0169 - val_nmse_accuracy: -10.7502 - val_bit_error_ratio: 0.0745\n",
      "Epoch 16/30\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0172 - nmse_accuracy: -10.8059 - bit_error_ratio: 0.0749 - val_loss: 0.0169 - val_nmse_accuracy: -10.7482 - val_bit_error_ratio: 0.0760\n",
      "Epoch 17/30\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0171 - nmse_accuracy: -10.8139 - bit_error_ratio: 0.0750 - val_loss: 0.0169 - val_nmse_accuracy: -10.7371 - val_bit_error_ratio: 0.0776\n",
      "Epoch 18/30\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0170 - nmse_accuracy: -10.8305 - bit_error_ratio: 0.0750 - val_loss: 0.0167 - val_nmse_accuracy: -10.7817 - val_bit_error_ratio: 0.0755\n",
      "Epoch 19/30\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0170 - nmse_accuracy: -10.8806 - bit_error_ratio: 0.0750 - val_loss: 0.0167 - val_nmse_accuracy: -10.7879 - val_bit_error_ratio: 0.0749\n",
      "Epoch 20/30\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0169 - nmse_accuracy: -10.8494 - bit_error_ratio: 0.0750 - val_loss: 0.0167 - val_nmse_accuracy: -10.7844 - val_bit_error_ratio: 0.0746\n",
      "Epoch 21/30\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0169 - nmse_accuracy: -10.9025 - bit_error_ratio: 0.0750 - val_loss: 0.0166 - val_nmse_accuracy: -10.8081 - val_bit_error_ratio: 0.0730\n",
      "Epoch 22/30\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0169 - nmse_accuracy: -10.8427 - bit_error_ratio: 0.0750 - val_loss: 0.0166 - val_nmse_accuracy: -10.8074 - val_bit_error_ratio: 0.0740\n",
      "Epoch 23/30\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0169 - nmse_accuracy: -10.9320 - bit_error_ratio: 0.0750 - val_loss: 0.0166 - val_nmse_accuracy: -10.8121 - val_bit_error_ratio: 0.0740\n",
      "Epoch 24/30\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0169 - nmse_accuracy: -10.8685 - bit_error_ratio: 0.0750 - val_loss: 0.0166 - val_nmse_accuracy: -10.8074 - val_bit_error_ratio: 0.0753\n",
      "Epoch 25/30\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0168 - nmse_accuracy: -10.9065 - bit_error_ratio: 0.0750 - val_loss: 0.0166 - val_nmse_accuracy: -10.8223 - val_bit_error_ratio: 0.0739\n",
      "Epoch 26/30\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0168 - nmse_accuracy: -10.8868 - bit_error_ratio: 0.0750 - val_loss: 0.0165 - val_nmse_accuracy: -10.8554 - val_bit_error_ratio: 0.0741\n",
      "Epoch 27/30\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0168 - nmse_accuracy: -10.9018 - bit_error_ratio: 0.0750 - val_loss: 0.0165 - val_nmse_accuracy: -10.8445 - val_bit_error_ratio: 0.0751\n",
      "Epoch 28/30\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0168 - nmse_accuracy: -10.9132 - bit_error_ratio: 0.0750 - val_loss: 0.0164 - val_nmse_accuracy: -10.8677 - val_bit_error_ratio: 0.0740\n",
      "Epoch 29/30\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0167 - nmse_accuracy: -10.9017 - bit_error_ratio: 0.0750 - val_loss: 0.0164 - val_nmse_accuracy: -10.8557 - val_bit_error_ratio: 0.0740\n",
      "Epoch 30/30\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0167 - nmse_accuracy: -10.9175 - bit_error_ratio: 0.0750 - val_loss: 0.0164 - val_nmse_accuracy: -10.8653 - val_bit_error_ratio: 0.0705\n"
     ]
    }
   ],
   "source": [
    "estimator_middel.compile(\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    metrics=[kt.NMSE_Accuracy(), kt.Bit_Error_Ratio_Threshold_0_01()],\n",
    ")\n",
    "\n",
    "log_dir=\"./temp10/logs/fit/\" + datetime.datetime.now().strftime(\"estimator_middel_%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "history = estimator_middel.fit(y_set_10dB, h_set_10dB, batch_size=1000, epochs=30, validation_data=(y_test_10dB, h_test_10dB), callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"estimator_big\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bp1 (BatchNormalization)     (3, 50)                   200       \n",
      "_________________________________________________________________\n",
      "layer1 (Dense)               (3, 150)                  7650      \n",
      "_________________________________________________________________\n",
      "bp2 (BatchNormalization)     (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "bp3 (BatchNormalization)     (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer3 (Dense)               (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "pb4 (BatchNormalization)     (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer4 (Dense)               (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "pb5 (BatchNormalization)     (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer5 (Dense)               (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "pb6 (BatchNormalization)     (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer6 (Dense)               (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "pb7 (BatchNormalization)     (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer7 (Dense)               (3, 100)                  15100     \n",
      "=================================================================\n",
      "Total params: 139,800\n",
      "Trainable params: 137,900\n",
      "Non-trainable params: 1,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "estimator_big = keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp1\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer1\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp2\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer2\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp3\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer3\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"pb4\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer4\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"pb5\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer5\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"pb6\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer6\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"pb7\"),\n",
    "        layers.Dense(user_number, activation=\"relu\", name=\"layer7\"),\n",
    "    ],name = 'estimator_big'\n",
    ")\n",
    "# Call model on a test input\n",
    "y = tf.ones((3, code_length))\n",
    "x_hat = estimator_big(y)\n",
    "estimator_big.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1000/1000 [==============================] - 33s 30ms/step - loss: 0.1231 - nmse_accuracy: -2.4944 - bit_error_ratio: 0.2749 - val_loss: 0.0322 - val_nmse_accuracy: -7.9492 - val_bit_error_ratio: 0.0919\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0253 - nmse_accuracy: -9.1314 - bit_error_ratio: 0.0787 - val_loss: 0.0214 - val_nmse_accuracy: -9.7184 - val_bit_error_ratio: 0.0795\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.0200 - nmse_accuracy: -10.1862 - bit_error_ratio: 0.0710 - val_loss: 0.0190 - val_nmse_accuracy: -10.2245 - val_bit_error_ratio: 0.0772\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.0181 - nmse_accuracy: -10.6000 - bit_error_ratio: 0.0688 - val_loss: 0.0171 - val_nmse_accuracy: -10.6652 - val_bit_error_ratio: 0.0700\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0169 - nmse_accuracy: -10.8847 - bit_error_ratio: 0.0675 - val_loss: 0.0161 - val_nmse_accuracy: -10.9372 - val_bit_error_ratio: 0.0661\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0160 - nmse_accuracy: -11.0870 - bit_error_ratio: 0.0667 - val_loss: 0.0156 - val_nmse_accuracy: -11.0556 - val_bit_error_ratio: 0.0667\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0155 - nmse_accuracy: -11.2320 - bit_error_ratio: 0.0662 - val_loss: 0.0150 - val_nmse_accuracy: -11.2137 - val_bit_error_ratio: 0.0645\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0150 - nmse_accuracy: -11.3131 - bit_error_ratio: 0.0660 - val_loss: 0.0147 - val_nmse_accuracy: -11.2884 - val_bit_error_ratio: 0.0661\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.0147 - nmse_accuracy: -11.4475 - bit_error_ratio: 0.0658 - val_loss: 0.0144 - val_nmse_accuracy: -11.3621 - val_bit_error_ratio: 0.0648\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.0145 - nmse_accuracy: -11.4902 - bit_error_ratio: 0.0659 - val_loss: 0.0142 - val_nmse_accuracy: -11.4484 - val_bit_error_ratio: 0.0667\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 0.0142 - nmse_accuracy: -11.5725 - bit_error_ratio: 0.0659 - val_loss: 0.0140 - val_nmse_accuracy: -11.4817 - val_bit_error_ratio: 0.0661\n",
      "Epoch 12/30\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.0141 - nmse_accuracy: -11.6538 - bit_error_ratio: 0.0660 - val_loss: 0.0139 - val_nmse_accuracy: -11.5153 - val_bit_error_ratio: 0.0650\n",
      "Epoch 13/30\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.0139 - nmse_accuracy: -11.6721 - bit_error_ratio: 0.0659 - val_loss: 0.0138 - val_nmse_accuracy: -11.5571 - val_bit_error_ratio: 0.0677\n",
      "Epoch 14/30\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.0137 - nmse_accuracy: -11.7173 - bit_error_ratio: 0.0658 - val_loss: 0.0135 - val_nmse_accuracy: -11.6119 - val_bit_error_ratio: 0.0682\n",
      "Epoch 15/30\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.0136 - nmse_accuracy: -11.7529 - bit_error_ratio: 0.0658 - val_loss: 0.0135 - val_nmse_accuracy: -11.6520 - val_bit_error_ratio: 0.0659\n",
      "Epoch 16/30\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0135 - nmse_accuracy: -11.7652 - bit_error_ratio: 0.0658 - val_loss: 0.0134 - val_nmse_accuracy: -11.6621 - val_bit_error_ratio: 0.0675\n",
      "Epoch 17/30\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 0.0134 - nmse_accuracy: -11.7774 - bit_error_ratio: 0.0659 - val_loss: 0.0132 - val_nmse_accuracy: -11.7256 - val_bit_error_ratio: 0.0646\n",
      "Epoch 18/30\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.0133 - nmse_accuracy: -11.8506 - bit_error_ratio: 0.0660 - val_loss: 0.0132 - val_nmse_accuracy: -11.7450 - val_bit_error_ratio: 0.0658\n",
      "Epoch 19/30\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 0.0133 - nmse_accuracy: -11.8311 - bit_error_ratio: 0.0658 - val_loss: 0.0130 - val_nmse_accuracy: -11.7797 - val_bit_error_ratio: 0.0640\n",
      "Epoch 20/30\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.0132 - nmse_accuracy: -11.8396 - bit_error_ratio: 0.0659 - val_loss: 0.0129 - val_nmse_accuracy: -11.8196 - val_bit_error_ratio: 0.0639\n",
      "Epoch 21/30\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.0131 - nmse_accuracy: -11.8740 - bit_error_ratio: 0.0658 - val_loss: 0.0129 - val_nmse_accuracy: -11.8150 - val_bit_error_ratio: 0.0658\n",
      "Epoch 22/30\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.0131 - nmse_accuracy: -11.8807 - bit_error_ratio: 0.0658 - val_loss: 0.0130 - val_nmse_accuracy: -11.7934 - val_bit_error_ratio: 0.0675\n",
      "Epoch 23/30\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0131 - nmse_accuracy: -11.8980 - bit_error_ratio: 0.0660 - val_loss: 0.0129 - val_nmse_accuracy: -11.8302 - val_bit_error_ratio: 0.0673\n",
      "Epoch 24/30\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.0130 - nmse_accuracy: -11.9714 - bit_error_ratio: 0.0659 - val_loss: 0.0127 - val_nmse_accuracy: -11.8781 - val_bit_error_ratio: 0.0642\n",
      "Epoch 25/30\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.0129 - nmse_accuracy: -11.9221 - bit_error_ratio: 0.0658 - val_loss: 0.0127 - val_nmse_accuracy: -11.8903 - val_bit_error_ratio: 0.0667\n",
      "Epoch 26/30\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.0129 - nmse_accuracy: -11.9786 - bit_error_ratio: 0.0658 - val_loss: 0.0128 - val_nmse_accuracy: -11.8576 - val_bit_error_ratio: 0.0670\n",
      "Epoch 27/30\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0129 - nmse_accuracy: -11.9786 - bit_error_ratio: 0.0658 - val_loss: 0.0126 - val_nmse_accuracy: -11.9255 - val_bit_error_ratio: 0.0644\n",
      "Epoch 28/30\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 0.0128 - nmse_accuracy: -12.0311 - bit_error_ratio: 0.0657 - val_loss: 0.0126 - val_nmse_accuracy: -11.9119 - val_bit_error_ratio: 0.0644\n",
      "Epoch 29/30\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.0128 - nmse_accuracy: -11.9790 - bit_error_ratio: 0.0657 - val_loss: 0.0126 - val_nmse_accuracy: -11.9307 - val_bit_error_ratio: 0.0654\n",
      "Epoch 30/30\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.0128 - nmse_accuracy: -11.9824 - bit_error_ratio: 0.0656 - val_loss: 0.0126 - val_nmse_accuracy: -11.9372 - val_bit_error_ratio: 0.0644\n"
     ]
    }
   ],
   "source": [
    "estimator_big.compile(\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    metrics=[kt.NMSE_Accuracy(), kt.Bit_Error_Ratio_Threshold_0_01()],\n",
    ")\n",
    "\n",
    "log_dir=\"./temp10/logs/fit/\" + datetime.datetime.now().strftime(\"estimator_big_%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "history = estimator_big.fit(y_set_10dB, h_set_10dB, batch_size=1000, epochs=30, validation_data=(y_test_10dB, h_test_10dB), callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"estimator_wide\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bp1 (BatchNormalization)     (3, 50)                   200       \n",
      "_________________________________________________________________\n",
      "layer1 (Dense)               (3, 300)                  15300     \n",
      "_________________________________________________________________\n",
      "bp2 (BatchNormalization)     (3, 300)                  1200      \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (3, 300)                  90300     \n",
      "_________________________________________________________________\n",
      "bp3 (BatchNormalization)     (3, 300)                  1200      \n",
      "_________________________________________________________________\n",
      "layer3 (Dense)               (3, 300)                  90300     \n",
      "_________________________________________________________________\n",
      "pb4 (BatchNormalization)     (3, 300)                  1200      \n",
      "_________________________________________________________________\n",
      "layer4 (Dense)               (3, 100)                  30100     \n",
      "=================================================================\n",
      "Total params: 229,800\n",
      "Trainable params: 227,900\n",
      "Non-trainable params: 1,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "estimator_wide = keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp1\"),\n",
    "        layers.Dense((user_number + code_length) * 2, activation=\"relu\", name=\"layer1\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp2\"),\n",
    "        layers.Dense((user_number + code_length) * 2, activation=\"relu\", name=\"layer2\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp3\"),\n",
    "        layers.Dense((user_number + code_length) * 2, activation=\"relu\", name=\"layer3\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"pb4\"),\n",
    "        layers.Dense(user_number, activation=\"relu\", name=\"layer4\"),\n",
    "    ],name = 'estimator_wide'\n",
    ")\n",
    "# Call model on a test input\n",
    "y = tf.ones((3, code_length))\n",
    "x_hat = estimator_wide(y)\n",
    "estimator_wide.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1000/1000 [==============================] - 27s 26ms/step - loss: 0.0857 - nmse_accuracy: -inf - bit_error_ratio: 0.1884 - val_loss: 0.0248 - val_nmse_accuracy: -9.1335 - val_bit_error_ratio: 0.0862\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.0209 - nmse_accuracy: -10.0034 - bit_error_ratio: 0.0682 - val_loss: 0.0183 - val_nmse_accuracy: -10.4070 - val_bit_error_ratio: 0.0690\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.0177 - nmse_accuracy: -10.6978 - bit_error_ratio: 0.0649 - val_loss: 0.0164 - val_nmse_accuracy: -10.8814 - val_bit_error_ratio: 0.0624\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 31s 31ms/step - loss: 0.0162 - nmse_accuracy: -11.0308 - bit_error_ratio: 0.0639 - val_loss: 0.0156 - val_nmse_accuracy: -11.0828 - val_bit_error_ratio: 0.0618\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.0155 - nmse_accuracy: -11.2318 - bit_error_ratio: 0.0637 - val_loss: 0.0150 - val_nmse_accuracy: -11.2162 - val_bit_error_ratio: 0.0627\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 0.0149 - nmse_accuracy: -11.4096 - bit_error_ratio: 0.0634 - val_loss: 0.0145 - val_nmse_accuracy: -11.3753 - val_bit_error_ratio: 0.0596\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.0145 - nmse_accuracy: -11.4488 - bit_error_ratio: 0.0633 - val_loss: 0.0143 - val_nmse_accuracy: -11.4074 - val_bit_error_ratio: 0.0649\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.0142 - nmse_accuracy: -11.5633 - bit_error_ratio: 0.0633 - val_loss: 0.0141 - val_nmse_accuracy: -11.5031 - val_bit_error_ratio: 0.0615\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.0140 - nmse_accuracy: -11.6391 - bit_error_ratio: 0.0632 - val_loss: 0.0138 - val_nmse_accuracy: -11.5640 - val_bit_error_ratio: 0.0655\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0138 - nmse_accuracy: -11.6892 - bit_error_ratio: 0.0629 - val_loss: 0.0136 - val_nmse_accuracy: -11.6408 - val_bit_error_ratio: 0.0612\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.0136 - nmse_accuracy: -11.7500 - bit_error_ratio: 0.0627 - val_loss: 0.0135 - val_nmse_accuracy: -11.6686 - val_bit_error_ratio: 0.0629\n",
      "Epoch 12/30\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.0135 - nmse_accuracy: -11.8164 - bit_error_ratio: 0.0625 - val_loss: 0.0134 - val_nmse_accuracy: -11.7154 - val_bit_error_ratio: 0.0614\n",
      "Epoch 13/30\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.0134 - nmse_accuracy: -11.8448 - bit_error_ratio: 0.0624 - val_loss: 0.0132 - val_nmse_accuracy: -11.7586 - val_bit_error_ratio: 0.0617\n",
      "Epoch 14/30\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.0133 - nmse_accuracy: -11.8607 - bit_error_ratio: 0.0623 - val_loss: 0.0131 - val_nmse_accuracy: -11.7779 - val_bit_error_ratio: 0.0621\n",
      "Epoch 15/30\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.0132 - nmse_accuracy: -11.8867 - bit_error_ratio: 0.0620 - val_loss: 0.0131 - val_nmse_accuracy: -11.8107 - val_bit_error_ratio: 0.0604\n",
      "Epoch 16/30\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 0.0131 - nmse_accuracy: -11.9233 - bit_error_ratio: 0.0619 - val_loss: 0.0130 - val_nmse_accuracy: -11.8158 - val_bit_error_ratio: 0.0613\n",
      "Epoch 17/30\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0130 - nmse_accuracy: -11.9348 - bit_error_ratio: 0.0619 - val_loss: 0.0130 - val_nmse_accuracy: -11.8409 - val_bit_error_ratio: 0.0609\n",
      "Epoch 18/30\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.0129 - nmse_accuracy: -11.9506 - bit_error_ratio: 0.0616 - val_loss: 0.0129 - val_nmse_accuracy: -11.8481 - val_bit_error_ratio: 0.0634\n",
      "Epoch 19/30\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.0129 - nmse_accuracy: -11.9753 - bit_error_ratio: 0.0615 - val_loss: 0.0128 - val_nmse_accuracy: -11.8933 - val_bit_error_ratio: 0.0597\n",
      "Epoch 20/30\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.0128 - nmse_accuracy: -inf - bit_error_ratio: 0.0612 - val_loss: 0.0127 - val_nmse_accuracy: -11.9236 - val_bit_error_ratio: 0.0599\n",
      "Epoch 21/30\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.0128 - nmse_accuracy: -12.0418 - bit_error_ratio: 0.0611 - val_loss: 0.0127 - val_nmse_accuracy: -11.9182 - val_bit_error_ratio: 0.0601\n",
      "Epoch 22/30\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.0127 - nmse_accuracy: -12.0245 - bit_error_ratio: 0.0609 - val_loss: 0.0126 - val_nmse_accuracy: -11.9495 - val_bit_error_ratio: 0.0606\n",
      "Epoch 23/30\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 0.0127 - nmse_accuracy: -12.0359 - bit_error_ratio: 0.0609 - val_loss: 0.0126 - val_nmse_accuracy: -11.9624 - val_bit_error_ratio: 0.0610\n",
      "Epoch 24/30\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.0126 - nmse_accuracy: -12.0835 - bit_error_ratio: 0.0608 - val_loss: 0.0125 - val_nmse_accuracy: -11.9837 - val_bit_error_ratio: 0.0599\n",
      "Epoch 25/30\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.0126 - nmse_accuracy: -12.1070 - bit_error_ratio: 0.0606 - val_loss: 0.0125 - val_nmse_accuracy: -11.9936 - val_bit_error_ratio: 0.0602\n",
      "Epoch 26/30\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 0.0125 - nmse_accuracy: -12.0884 - bit_error_ratio: 0.0606 - val_loss: 0.0125 - val_nmse_accuracy: -11.9767 - val_bit_error_ratio: 0.0598\n",
      "Epoch 27/30\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.0125 - nmse_accuracy: -12.1352 - bit_error_ratio: 0.0606 - val_loss: 0.0125 - val_nmse_accuracy: -11.9971 - val_bit_error_ratio: 0.0609\n",
      "Epoch 28/30\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 0.0125 - nmse_accuracy: -12.1052 - bit_error_ratio: 0.0606 - val_loss: 0.0124 - val_nmse_accuracy: -12.0144 - val_bit_error_ratio: 0.0593\n",
      "Epoch 29/30\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.0124 - nmse_accuracy: -12.1094 - bit_error_ratio: 0.0605 - val_loss: 0.0124 - val_nmse_accuracy: -12.0263 - val_bit_error_ratio: 0.0594\n",
      "Epoch 30/30\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 0.0124 - nmse_accuracy: -12.1505 - bit_error_ratio: 0.0604 - val_loss: 0.0124 - val_nmse_accuracy: -12.0303 - val_bit_error_ratio: 0.0611\n"
     ]
    }
   ],
   "source": [
    "estimator_wide.compile(\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    metrics=[kt.NMSE_Accuracy(), kt.Bit_Error_Ratio_Threshold_0_01()],\n",
    ")\n",
    "\n",
    "log_dir=\"./temp10/logs/fit/\" + datetime.datetime.now().strftime(\"estimator_wide_%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "history = estimator_wide.fit(y_set_10dB, h_set_10dB, batch_size=1000, epochs=30, validation_data=(y_test_10dB, h_test_10dB), callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"estimator_long\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bp1 (BatchNormalization)     (3, 50)                   200       \n",
      "_________________________________________________________________\n",
      "layer1 (Dense)               (3, 150)                  7650      \n",
      "_________________________________________________________________\n",
      "bp2 (BatchNormalization)     (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "bp3 (BatchNormalization)     (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer3 (Dense)               (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "pb4 (BatchNormalization)     (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer4 (Dense)               (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "pb5 (BatchNormalization)     (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer5 (Dense)               (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "pb6 (BatchNormalization)     (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer6 (Dense)               (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "pb7 (BatchNormalization)     (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer7 (Dense)               (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "pb8 (BatchNormalization)     (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer8 (Dense)               (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "pb9 (BatchNormalization)     (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer9 (Dense)               (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "pb10 (BatchNormalization)    (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer10 (Dense)              (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "pb11 (BatchNormalization)    (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer11 (Dense)              (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "pb12 (BatchNormalization)    (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer12 (Dense)              (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "pb13 (BatchNormalization)    (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer13 (Dense)              (3, 100)                  15100     \n",
      "=================================================================\n",
      "Total params: 279,300\n",
      "Trainable params: 275,600\n",
      "Non-trainable params: 3,700\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "estimator_long = keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp1\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer1\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp2\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer2\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bp3\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer3\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"pb4\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer4\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"pb5\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer5\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"pb6\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer6\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"pb7\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer7\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"pb8\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer8\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"pb9\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer9\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"pb10\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer10\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"pb11\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer11\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"pb12\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer12\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"pb13\"),\n",
    "        layers.Dense(user_number, activation=\"relu\", name=\"layer13\"),\n",
    "    ],name = 'estimator_long'\n",
    ")\n",
    "# Call model on a test input\n",
    "y = tf.ones((3, code_length))\n",
    "x_hat = estimator_long(y)\n",
    "estimator_long.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1000/1000 [==============================] - 56s 51ms/step - loss: 0.1686 - nmse_accuracy: -0.9080 - bit_error_ratio: 0.3883 - val_loss: 0.1164 - val_nmse_accuracy: -2.0824 - val_bit_error_ratio: 0.1722\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0612 - nmse_accuracy: -5.5146 - bit_error_ratio: 0.1055 - val_loss: 0.0440 - val_nmse_accuracy: -6.5987 - val_bit_error_ratio: 0.0978\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.0324 - nmse_accuracy: -8.1962 - bit_error_ratio: 0.0786 - val_loss: 0.0314 - val_nmse_accuracy: -8.0522 - val_bit_error_ratio: 0.0894\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.0250 - nmse_accuracy: -9.3162 - bit_error_ratio: 0.0705 - val_loss: 0.0256 - val_nmse_accuracy: -8.9883 - val_bit_error_ratio: 0.0802\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.0224 - nmse_accuracy: -9.7605 - bit_error_ratio: 0.0675 - val_loss: 0.0224 - val_nmse_accuracy: -9.5655 - val_bit_error_ratio: 0.0747\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.0203 - nmse_accuracy: -10.1314 - bit_error_ratio: 0.0649 - val_loss: 0.0203 - val_nmse_accuracy: -9.9323 - val_bit_error_ratio: 0.0727\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.0187 - nmse_accuracy: -10.4901 - bit_error_ratio: 0.0628 - val_loss: 0.0186 - val_nmse_accuracy: -10.3101 - val_bit_error_ratio: 0.0695\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.0175 - nmse_accuracy: -10.7387 - bit_error_ratio: 0.0614 - val_loss: 0.0170 - val_nmse_accuracy: -10.6915 - val_bit_error_ratio: 0.0629\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.0167 - nmse_accuracy: -10.9225 - bit_error_ratio: 0.0602 - val_loss: 0.0164 - val_nmse_accuracy: -10.8561 - val_bit_error_ratio: 0.0627\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.0160 - nmse_accuracy: -inf - bit_error_ratio: 0.0591 - val_loss: 0.0161 - val_nmse_accuracy: -10.8951 - val_bit_error_ratio: 0.0652\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.0155 - nmse_accuracy: -11.2315 - bit_error_ratio: 0.0583 - val_loss: 0.0156 - val_nmse_accuracy: -11.0224 - val_bit_error_ratio: 0.0641\n",
      "Epoch 12/30\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0151 - nmse_accuracy: -11.3421 - bit_error_ratio: 0.0578 - val_loss: 0.0155 - val_nmse_accuracy: -11.0354 - val_bit_error_ratio: 0.0640\n",
      "Epoch 13/30\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.0148 - nmse_accuracy: -11.3756 - bit_error_ratio: 0.0574 - val_loss: 0.0149 - val_nmse_accuracy: -11.2107 - val_bit_error_ratio: 0.0623\n",
      "Epoch 14/30\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.0146 - nmse_accuracy: -11.4970 - bit_error_ratio: 0.0570 - val_loss: 0.0145 - val_nmse_accuracy: -11.3280 - val_bit_error_ratio: 0.0611\n",
      "Epoch 15/30\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.0144 - nmse_accuracy: -11.5052 - bit_error_ratio: 0.0567 - val_loss: 0.0142 - val_nmse_accuracy: -11.4382 - val_bit_error_ratio: 0.0588\n",
      "Epoch 16/30\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.0142 - nmse_accuracy: -11.5305 - bit_error_ratio: 0.0564 - val_loss: 0.0142 - val_nmse_accuracy: -11.4121 - val_bit_error_ratio: 0.0584\n",
      "Epoch 17/30\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.0140 - nmse_accuracy: -11.6169 - bit_error_ratio: 0.0561 - val_loss: 0.0140 - val_nmse_accuracy: -11.4635 - val_bit_error_ratio: 0.0595\n",
      "Epoch 18/30\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.0139 - nmse_accuracy: -11.6847 - bit_error_ratio: 0.0560 - val_loss: 0.0137 - val_nmse_accuracy: -11.5541 - val_bit_error_ratio: 0.0579\n",
      "Epoch 19/30\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.0137 - nmse_accuracy: -11.7205 - bit_error_ratio: 0.0558 - val_loss: 0.0137 - val_nmse_accuracy: -11.5715 - val_bit_error_ratio: 0.0577\n",
      "Epoch 20/30\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.0136 - nmse_accuracy: -11.7985 - bit_error_ratio: 0.0557 - val_loss: 0.0135 - val_nmse_accuracy: -11.6428 - val_bit_error_ratio: 0.0590\n",
      "Epoch 21/30\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.0134 - nmse_accuracy: -11.7913 - bit_error_ratio: 0.0556 - val_loss: 0.0133 - val_nmse_accuracy: -11.7086 - val_bit_error_ratio: 0.0562\n",
      "Epoch 22/30\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.0133 - nmse_accuracy: -11.8335 - bit_error_ratio: 0.0554 - val_loss: 0.0133 - val_nmse_accuracy: -11.6733 - val_bit_error_ratio: 0.0596\n",
      "Epoch 23/30\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.0132 - nmse_accuracy: -11.8503 - bit_error_ratio: 0.0553 - val_loss: 0.0134 - val_nmse_accuracy: -11.6422 - val_bit_error_ratio: 0.0600\n",
      "Epoch 24/30\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0131 - nmse_accuracy: -11.8912 - bit_error_ratio: 0.0553 - val_loss: 0.0131 - val_nmse_accuracy: -11.7562 - val_bit_error_ratio: 0.0581\n",
      "Epoch 25/30\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0130 - nmse_accuracy: -11.9251 - bit_error_ratio: 0.0553 - val_loss: 0.0129 - val_nmse_accuracy: -11.8001 - val_bit_error_ratio: 0.0570\n",
      "Epoch 26/30\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0129 - nmse_accuracy: -12.0065 - bit_error_ratio: 0.0553 - val_loss: 0.0126 - val_nmse_accuracy: -11.9102 - val_bit_error_ratio: 0.0561\n",
      "Epoch 27/30\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.0128 - nmse_accuracy: -11.9418 - bit_error_ratio: 0.0553 - val_loss: 0.0126 - val_nmse_accuracy: -11.9210 - val_bit_error_ratio: 0.0561\n",
      "Epoch 28/30\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.0128 - nmse_accuracy: -11.9825 - bit_error_ratio: 0.0554 - val_loss: 0.0126 - val_nmse_accuracy: -11.8977 - val_bit_error_ratio: 0.0586\n",
      "Epoch 29/30\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.0127 - nmse_accuracy: -11.9982 - bit_error_ratio: 0.0553 - val_loss: 0.0122 - val_nmse_accuracy: -12.0606 - val_bit_error_ratio: 0.0559\n",
      "Epoch 30/30\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.0126 - nmse_accuracy: -12.0430 - bit_error_ratio: 0.0555 - val_loss: 0.0124 - val_nmse_accuracy: -11.9760 - val_bit_error_ratio: 0.0568\n"
     ]
    }
   ],
   "source": [
    "estimator_long.compile(\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    metrics=[kt.NMSE_Accuracy(), kt.Bit_Error_Ratio_Threshold_0_01()],\n",
    ")\n",
    "\n",
    "log_dir=\"./temp10/logs/fit/\" + datetime.datetime.now().strftime(\"estimator_long_%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "history = estimator_long.fit(y_set_10dB, h_set_10dB, batch_size=1000, epochs=30, validation_data=(y_test_10dB, h_test_10dB), callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"estimator_long_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bn1 (BatchNormalization)     (3, 50)                   200       \n",
      "_________________________________________________________________\n",
      "layer1 (Dense)               (3, 150)                  7650      \n",
      "_________________________________________________________________\n",
      "bn2 (BatchNormalization)     (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "bn3 (BatchNormalization)     (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer3 (Dense)               (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "bn4 (BatchNormalization)     (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer4 (Dense)               (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "bn5 (BatchNormalization)     (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer5 (Dense)               (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "bn6 (BatchNormalization)     (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer6 (Dense)               (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "bn7 (BatchNormalization)     (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer7 (Dense)               (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "bn8 (BatchNormalization)     (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer8 (Dense)               (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "bn9 (BatchNormalization)     (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer9 (Dense)               (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "bn10 (BatchNormalization)    (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer10 (Dense)              (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "bn11 (BatchNormalization)    (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer11 (Dense)              (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "bn12 (BatchNormalization)    (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer12 (Dense)              (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "bn13 (BatchNormalization)    (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer13 (Dense)              (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "bn14 (BatchNormalization)    (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer14 (Dense)              (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "bn15 (BatchNormalization)    (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer15 (Dense)              (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "bn16 (BatchNormalization)    (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer16 (Dense)              (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "bn17 (BatchNormalization)    (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer17 (Dense)              (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "bn18 (BatchNormalization)    (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer18 (Dense)              (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "bn19 (BatchNormalization)    (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer19 (Dense)              (3, 150)                  22650     \n",
      "_________________________________________________________________\n",
      "bn20 (BatchNormalization)    (3, 150)                  600       \n",
      "_________________________________________________________________\n",
      "layer20 (Dense)              (3, 100)                  15100     \n",
      "=================================================================\n",
      "Total params: 442,050\n",
      "Trainable params: 436,250\n",
      "Non-trainable params: 5,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "estimator_long_20 = keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.BatchNormalization(name=\"bn1\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer1\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bn2\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer2\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bn3\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer3\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bn4\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer4\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bn5\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer5\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bn6\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer6\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bn7\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer7\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bn8\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer8\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bn9\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer9\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bn10\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer10\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bn11\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer11\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bn12\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer12\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bn13\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer13\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bn14\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer14\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bn15\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer15\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bn16\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer16\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bn17\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer17\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bn18\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer18\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bn19\"),\n",
    "        layers.Dense(user_number + code_length, activation=\"relu\", name=\"layer19\"),\n",
    "        tf.keras.layers.BatchNormalization(name=\"bn20\"),\n",
    "        layers.Dense(user_number, activation=\"relu\", name=\"layer20\"),\n",
    "    ],name = 'estimator_long_20'\n",
    ")\n",
    "# Call model on a test input\n",
    "y = tf.ones((3, code_length))\n",
    "x_hat = estimator_long_20(y)\n",
    "estimator_long_20.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1000/1000 [==============================] - 71s 65ms/step - loss: 0.1879 - nmse_accuracy: -0.3319 - bit_error_ratio: 0.5947 - val_loss: 0.1540 - val_nmse_accuracy: -1.0730 - val_bit_error_ratio: 0.4859\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1364 - nmse_accuracy: -1.7762 - bit_error_ratio: 0.4696 - val_loss: 0.1328 - val_nmse_accuracy: -1.7400 - val_bit_error_ratio: 0.4121\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1214 - nmse_accuracy: -2.3159 - bit_error_ratio: 0.3886 - val_loss: 0.1211 - val_nmse_accuracy: -2.1770 - val_bit_error_ratio: 0.3661\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1126 - nmse_accuracy: -2.6746 - bit_error_ratio: 0.3414 - val_loss: 0.1112 - val_nmse_accuracy: -2.5779 - val_bit_error_ratio: 0.3246\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 79s 79ms/step - loss: 0.1061 - nmse_accuracy: -2.9655 - bit_error_ratio: 0.3088 - val_loss: 0.1027 - val_nmse_accuracy: -2.9014 - val_bit_error_ratio: 0.2990\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.1020 - nmse_accuracy: -3.1642 - bit_error_ratio: 0.2908 - val_loss: 0.1011 - val_nmse_accuracy: -3.0148 - val_bit_error_ratio: 0.2813\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0964 - nmse_accuracy: -3.3635 - bit_error_ratio: 0.2581 - val_loss: 0.0961 - val_nmse_accuracy: -3.2561 - val_bit_error_ratio: 0.2477\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0905 - nmse_accuracy: -3.7025 - bit_error_ratio: 0.2256 - val_loss: 0.0902 - val_nmse_accuracy: -3.5669 - val_bit_error_ratio: 0.2159\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0864 - nmse_accuracy: -3.8683 - bit_error_ratio: 0.2016 - val_loss: 0.0880 - val_nmse_accuracy: -3.7034 - val_bit_error_ratio: 0.1900\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.0834 - nmse_accuracy: -4.0681 - bit_error_ratio: 0.1843 - val_loss: 0.0841 - val_nmse_accuracy: -3.8864 - val_bit_error_ratio: 0.1799\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.0805 - nmse_accuracy: -4.2822 - bit_error_ratio: 0.1693 - val_loss: 3507.0657 - val_nmse_accuracy: 48.8255 - val_bit_error_ratio: 0.1679\n",
      "Epoch 12/30\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0781 - nmse_accuracy: -4.3953 - bit_error_ratio: 0.1587 - val_loss: 0.0791 - val_nmse_accuracy: -4.1951 - val_bit_error_ratio: 0.1564\n",
      "Epoch 13/30\n",
      "1000/1000 [==============================] - 93s 93ms/step - loss: 0.0762 - nmse_accuracy: -4.4748 - bit_error_ratio: 0.1502 - val_loss: 46.1158 - val_nmse_accuracy: 31.9806 - val_bit_error_ratio: 0.1564\n",
      "Epoch 14/30\n",
      "1000/1000 [==============================] - 86s 86ms/step - loss: 0.0739 - nmse_accuracy: -4.6288 - bit_error_ratio: 0.1444 - val_loss: 0.8506 - val_nmse_accuracy: 19.5172 - val_bit_error_ratio: 0.1704\n",
      "Epoch 15/30\n",
      "1000/1000 [==============================] - 92s 92ms/step - loss: 0.0715 - nmse_accuracy: -4.8056 - bit_error_ratio: 0.1381 - val_loss: 34.3971 - val_nmse_accuracy: 32.0390 - val_bit_error_ratio: 0.1392\n",
      "Epoch 16/30\n",
      "1000/1000 [==============================] - 82s 82ms/step - loss: 0.0695 - nmse_accuracy: -4.8856 - bit_error_ratio: 0.1293 - val_loss: 0.0744 - val_nmse_accuracy: -4.4254 - val_bit_error_ratio: 0.1338\n",
      "Epoch 17/30\n",
      "1000/1000 [==============================] - 82s 82ms/step - loss: 0.0671 - nmse_accuracy: -5.0798 - bit_error_ratio: 0.1193 - val_loss: 0.0712 - val_nmse_accuracy: -4.6454 - val_bit_error_ratio: 0.1259\n",
      "Epoch 18/30\n",
      "1000/1000 [==============================] - 86s 86ms/step - loss: 0.0639 - nmse_accuracy: -5.2634 - bit_error_ratio: 0.1109 - val_loss: 0.0683 - val_nmse_accuracy: -4.8267 - val_bit_error_ratio: 0.1198\n",
      "Epoch 19/30\n",
      "1000/1000 [==============================] - 99s 99ms/step - loss: 0.0619 - nmse_accuracy: -5.4504 - bit_error_ratio: 0.1049 - val_loss: 0.0670 - val_nmse_accuracy: -4.8764 - val_bit_error_ratio: 0.1200\n",
      "Epoch 20/30\n",
      "1000/1000 [==============================] - 95s 95ms/step - loss: 0.0601 - nmse_accuracy: -inf - bit_error_ratio: 0.1017 - val_loss: 0.0685 - val_nmse_accuracy: -4.8231 - val_bit_error_ratio: 0.1159\n",
      "Epoch 21/30\n",
      "1000/1000 [==============================] - 92s 92ms/step - loss: 0.0585 - nmse_accuracy: -5.6948 - bit_error_ratio: 0.0976 - val_loss: 0.0684 - val_nmse_accuracy: -4.7509 - val_bit_error_ratio: 0.1143\n",
      "Epoch 22/30\n",
      "1000/1000 [==============================] - 103s 103ms/step - loss: 0.0570 - nmse_accuracy: -5.7897 - bit_error_ratio: 0.0933 - val_loss: 0.0636 - val_nmse_accuracy: -5.1157 - val_bit_error_ratio: 0.1068\n",
      "Epoch 23/30\n",
      "1000/1000 [==============================] - 89s 89ms/step - loss: 0.0557 - nmse_accuracy: -5.9031 - bit_error_ratio: 0.0917 - val_loss: 0.0606 - val_nmse_accuracy: -5.3385 - val_bit_error_ratio: 0.1041\n",
      "Epoch 24/30\n",
      "1000/1000 [==============================] - 84s 84ms/step - loss: 0.0549 - nmse_accuracy: -5.9649 - bit_error_ratio: 0.0906 - val_loss: 0.0611 - val_nmse_accuracy: -5.2824 - val_bit_error_ratio: 0.1047\n",
      "Epoch 25/30\n",
      "1000/1000 [==============================] - 90s 90ms/step - loss: 0.0546 - nmse_accuracy: -5.9518 - bit_error_ratio: 0.0895 - val_loss: 0.0578 - val_nmse_accuracy: -5.5588 - val_bit_error_ratio: 0.0965\n",
      "Epoch 26/30\n",
      "1000/1000 [==============================] - 79s 79ms/step - loss: 0.0537 - nmse_accuracy: -6.0720 - bit_error_ratio: 0.0887 - val_loss: 0.0569 - val_nmse_accuracy: -5.6470 - val_bit_error_ratio: 0.0955\n",
      "Epoch 27/30\n",
      "1000/1000 [==============================] - 87s 87ms/step - loss: 0.0531 - nmse_accuracy: -6.1183 - bit_error_ratio: 0.0877 - val_loss: 0.0591 - val_nmse_accuracy: -5.4182 - val_bit_error_ratio: 0.1022\n",
      "Epoch 28/30\n",
      "1000/1000 [==============================] - 96s 96ms/step - loss: 0.0528 - nmse_accuracy: -6.1471 - bit_error_ratio: 0.0881 - val_loss: 0.0618 - val_nmse_accuracy: -5.2066 - val_bit_error_ratio: 0.1069\n",
      "Epoch 29/30\n",
      "1000/1000 [==============================] - 75s 75ms/step - loss: 0.0528 - nmse_accuracy: -6.1270 - bit_error_ratio: 0.0885 - val_loss: 0.0576 - val_nmse_accuracy: -5.5695 - val_bit_error_ratio: 0.1027\n",
      "Epoch 30/30\n",
      "1000/1000 [==============================] - 80s 80ms/step - loss: 0.0523 - nmse_accuracy: -6.1683 - bit_error_ratio: 0.0896 - val_loss: 0.0548 - val_nmse_accuracy: -5.8142 - val_bit_error_ratio: 0.0965\n"
     ]
    }
   ],
   "source": [
    "estimator_long_20.compile(\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    metrics=[kt.NMSE_Accuracy(), kt.Bit_Error_Ratio_Threshold_0_01()],\n",
    ")\n",
    "\n",
    "log_dir=\"./temp10/logs/fit/\" + datetime.datetime.now().strftime(\"estimator_long20_%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "history = estimator_long_20.fit(y_set_10dB, h_set_10dB, batch_size=1000, epochs=30, validation_data=(y_test_10dB, h_test_10dB), callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
